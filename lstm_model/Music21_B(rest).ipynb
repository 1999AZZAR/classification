{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program is referenced and modified from:\n",
    "> https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5  \n",
    "\n",
    "Reference article explaining how to improve the program:\n",
    "> https://david-exiga.medium.com/music-generation-using-lstm-neural-networks-44f6780a4c5  \n",
    "\n",
    "Additional Chinese program explanation:\n",
    "> https://github.com/xitu/gold-miner/blob/master/TODO1/how-to-generate-music-using-a-lstm-neural-network-in-keras.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: music21 in /usr/local/lib/python3.10/dist-packages (9.3.0)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.7.0)\n",
      "Requirement already satisfied: tensorflow[and-cuda] in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
      "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from music21) (5.2.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from music21) (1.4.2)\n",
      "Requirement already satisfied: jsonpickle in /usr/local/lib/python3.10/dist-packages (from music21) (4.0.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from music21) (3.9.3)\n",
      "Requirement already satisfied: more-itertools in /usr/lib/python3/dist-packages (from music21) (8.10.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from music21) (1.26.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from music21) (2.31.0)\n",
      "Requirement already satisfied: webcolors>=1.5 in /usr/local/lib/python3.10/dist-packages (from music21) (1.13)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.12.1)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\n",
      "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (23.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (5.29.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (69.0.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow[and-cuda]) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (2.18.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (0.37.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.5.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (12.5.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.5.82 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (12.5.82)\n",
      "Requirement already satisfied: nvidia-cuda-nvcc-cu12==12.5.82 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (12.5.82)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.5.82 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (12.5.82)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.5.82 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (12.5.82)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.3.0.75 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (9.3.0.75)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.3.61 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (11.2.3.61)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.6.82 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (10.3.6.82)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.3.83 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (11.6.3.83)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (12.5.1.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.5.82 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (12.5.82)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.42.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->music21) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->music21) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->music21) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->music21) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (3.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->music21) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (2.8.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (2.1.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install dependency \n",
    "# music21 Introduction: https://juejin.cn/post/7063827463058489352\n",
    "! pip install music21 keras tensorflow[and-cuda] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 14:48:38.716375: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733150918.730050  208020 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733150918.734204  208020 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-02 14:48:38.750595: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# For reading files\n",
    "import glob\n",
    "# array processing\n",
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "# keras for building deep learning model\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, TimeDistributed\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# 使用music21來進行midi檔案的操作\n",
    "from music21 import converter, instrument, note, chord, stream, duration\n",
    "# music21 介紹: https://juejin.cn/post/7063827463058489352\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 從目錄下的 midi 文件中獲取所有的音符和和弦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ./midi_songs/Boys.mid\n",
      "Parsing ./midi_songs/Because.mid\n",
      "Parsing ./midi_songs/Bungalow Bill.mid\n",
      "Parsing ./midi_songs/All Together Now.mid\n",
      "Parsing ./midi_songs/All I've Got To Do.mid\n",
      "Parsing ./midi_songs/A Hard Days Night.mid\n",
      "Parsing ./midi_songs/And I Love Her.mid\n",
      "Parsing ./midi_songs/Ask Me Why.mid\n",
      "Parsing ./midi_songs/Anna (Go To Him).mid\n",
      "Parsing ./midi_songs/Act Naturally.mid\n",
      "Parsing ./midi_songs/Across The Universe.mid\n",
      "Parsing ./midi_songs/Call Your Name.mid\n",
      "Parsing ./midi_songs/Chains.mid\n",
      "Parsing ./midi_songs/Bad Boy.mid\n",
      "Parsing ./midi_songs/Doctor Robert.mid\n",
      "Parsing ./midi_songs/Devil In Her Heart.mid\n",
      "Parsing ./midi_songs/Don't Bother Me.mid\n",
      "Parsing ./midi_songs/Baby You're A Rich Man.mid\n",
      "Parsing ./midi_songs/Can't Buy Me Love.mid\n",
      "Parsing ./midi_songs/Baby It's You.mid\n",
      "Parsing ./midi_songs/All My Loving.mid\n",
      "Parsing ./midi_songs/Any Time At All.mid\n",
      "Parsing ./midi_songs/Carry That Weight.mid\n",
      "Parsing ./midi_songs/Baby's In Black.mid\n",
      "Parsing ./midi_songs/And Your Bird Can Sing.mid\n",
      "Parsing ./midi_songs/Being For The Benefit Of Mr Kite.mid\n",
      "Parsing ./midi_songs/A Taste Of Honey.mid\n",
      "Parsing ./midi_songs/Blackbird.mid\n",
      "Parsing ./midi_songs/Dear Prudence.mid\n",
      "Parsing ./midi_songs/All You Need Is Love.mid\n",
      "Parsing ./midi_songs/Blue Jay Way.mid\n",
      "Parsing ./midi_songs/Dig It.mid\n",
      "Parsing ./midi_songs/Do You Want To Know A Secret.mid\n",
      "Parsing ./midi_songs/Ballad Of John And Yoko.mid\n",
      "Parsing ./midi_songs/Back In The USSR.mid\n",
      "Parsing ./midi_songs/Dig A Pony.mid\n",
      "Parsing ./midi_songs/Birthday.mid\n",
      "Parsing ./midi_songs/Day Tripper.mid\n",
      "Parsing ./midi_songs/Dizzy Miss Lizzie.mid\n",
      "Parsing ./midi_songs/Everybody's Trying To Be My Baby.mid\n",
      "Parsing ./midi_songs/Everybody's Got Something To Hide.mid\n",
      "Parsing ./midi_songs/Another Girl.mid\n",
      "Parsing ./midi_songs/Don't Let Me Down.mid\n",
      "Parsing ./midi_songs/Eleanor Rigby.mid\n",
      "Parsing ./midi_songs/Come Together.mid\n",
      "Parsing ./midi_songs/Every Little Thing.mid\n",
      "Parsing ./midi_songs/Flying.mid\n",
      "Parsing ./midi_songs/Cry Baby Cry.mid\n",
      "Parsing ./midi_songs/Follow The Sun.mid\n",
      "Parsing ./midi_songs/Cry Instead.mid\n",
      "Parsing ./midi_songs/Am The Walrus.mid\n",
      "Parsing ./midi_songs/Fixing A Hole.mid\n",
      "Parsing ./midi_songs/Golden Slumbers.mid\n",
      "Parsing ./midi_songs/Don't Pass Me By.mid\n",
      "Parsing ./midi_songs/Good Night.mid\n",
      "Parsing ./midi_songs/Eight Days A Week.mid\n",
      "Parsing ./midi_songs/Glass Onion.mid\n",
      "Parsing ./midi_songs/Good Morning Good Morning.mid\n",
      "Parsing ./midi_songs/Good Day Sunshine.mid\n",
      "Parsing ./midi_songs/From Me To You.mid\n",
      "Parsing ./midi_songs/Got To Get You Into My Life.mid\n",
      "Parsing ./midi_songs/Drive My Car.mid\n",
      "Parsing ./midi_songs/For You Blue.mid\n",
      "Parsing ./midi_songs/Get You.mid\n",
      "Parsing ./midi_songs/For No One.mid\n",
      "Parsing ./midi_songs/Getting Better.mid\n",
      "Parsing ./midi_songs/Girl.mid\n",
      "Parsing ./midi_songs/Her Majesty.mid\n",
      "Parsing ./midi_songs/Don't Want To Spoil The Party.mid\n",
      "Parsing ./midi_songs/Here There And Everywhere.mid\n",
      "Parsing ./midi_songs/Happiness Is A Warm Gun.mid\n",
      "Parsing ./midi_songs/I Will.mid\n",
      "Parsing ./midi_songs/Get Back.mid\n",
      "Parsing ./midi_songs/Honey Pie.mid\n",
      "Parsing ./midi_songs/I Saw Her Standing There.mid\n",
      "Parsing ./midi_songs/I Wanna Be Your Man.mid\n",
      "Parsing ./midi_songs/Here Comes The Sun.mid\n",
      "Parsing ./midi_songs/I Feel Fine.mid\n",
      "Parsing ./midi_songs/I Want To Hold Your Hand.mid\n",
      "Parsing ./midi_songs/Help.mid\n",
      "Parsing ./midi_songs/Hold Me Tight.mid\n",
      "Parsing ./midi_songs/Julia.mid\n",
      "Parsing ./midi_songs/Helter Skelter.mid\n",
      "Parsing ./midi_songs/I'll Be Back.mid\n",
      "Parsing ./midi_songs/Hello Goodbye.mid\n",
      "Parsing ./midi_songs/I Want You.mid\n",
      "Parsing ./midi_songs/It Won't Be Long.mid\n",
      "Parsing ./midi_songs/I'm Down.mid\n",
      "Parsing ./midi_songs/I'm Happy Just To Dance With You.mid\n",
      "Parsing ./midi_songs/I'm Only Sleeping.mid\n",
      "Parsing ./midi_songs/In My Life.mid\n",
      "Parsing ./midi_songs/Honey Don't.mid\n",
      "Parsing ./midi_songs/Hey Jude.mid\n",
      "Parsing ./midi_songs/Hey Bulldog.mid\n",
      "Parsing ./midi_songs/I'm Looking Through You.mid\n",
      "Parsing ./midi_songs/Lucy In The Sky With Diamonds.mid\n",
      "Parsing ./midi_songs/Kansas City.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/music21/midi/translate.py:874: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=10, channel=None, data=b'Marca\\xe7\\xe3o'>; getting generic Instrument\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ./midi_songs/It's All Too Much.mid\n",
      "Parsing ./midi_songs/Sgt Pepper Reprise.mid\n",
      "Parsing ./midi_songs/Maggie Mae.mid\n",
      "Parsing ./midi_songs/It's Only Love.mid\n",
      "Parsing ./midi_songs/If I Needed Someone.mid\n",
      "Parsing ./midi_songs/Love Me Do.mid\n",
      "Parsing ./midi_songs/Lovely Rita.mid\n",
      "Parsing ./midi_songs/Mean Mr Mustard.mid\n",
      "Parsing ./midi_songs/Let It Be.mid\n",
      "Parsing ./midi_songs/Lady Madonna.mid\n",
      "Parsing ./midi_songs/I've Got A Feeling.mid\n",
      "Parsing ./midi_songs/Long And Winding Road.mid\n",
      "Parsing ./midi_songs/Sexy Sadie.mid\n",
      "Parsing ./midi_songs/Long Long Long.mid\n",
      "Parsing ./midi_songs/Magical Mystery Tour.mid\n",
      "Parsing ./midi_songs/Maxwell's Silver Hammer.mid\n",
      "Parsing ./midi_songs/Sun King.mid\n",
      "Parsing ./midi_songs/Wild Honey_Pie.mid\n",
      "Parsing ./midi_songs/Sgt Pepper.mid\n",
      "Parsing ./midi_songs/The Inner Light.mid\n",
      "Parsing ./midi_songs/Nowhere Man.mid\n",
      "Parsing ./midi_songs/Penny Lane.mid\n",
      "Parsing ./midi_songs/PS I Love You.mid\n",
      "Parsing ./midi_songs/Matchbox.mid\n",
      "Parsing ./midi_songs/No Reply.mid\n",
      "Parsing ./midi_songs/Mr Moonlight.mid\n",
      "Parsing ./midi_songs/Need You.mid\n",
      "Parsing ./midi_songs/Run For Your Life.mid\n",
      "Parsing ./midi_songs/Mother Natures Son.mid\n",
      "Parsing ./midi_songs/Norwegian Wood.mid\n",
      "Parsing ./midi_songs/Wait.mid\n",
      "Parsing ./midi_songs/Me Mine.mid\n",
      "Parsing ./midi_songs/What Goes On.mid\n",
      "Parsing ./midi_songs/Please Please Me.mid\n",
      "Parsing ./midi_songs/One After 909.mid\n",
      "Parsing ./midi_songs/Only A Northern Song.mid\n",
      "Parsing ./midi_songs/Piggies.mid\n",
      "Parsing ./midi_songs/What You're Doing.mid\n",
      "Parsing ./midi_songs/The End.mid\n",
      "Parsing ./midi_songs/Rain.mid\n",
      "Parsing ./midi_songs/Rocky Raccoon.mid\n",
      "Parsing ./midi_songs/She Came In Through The Bathroom Window.mid\n",
      "Parsing ./midi_songs/Please Mister Postman.mid\n",
      "Parsing ./midi_songs/She's Leaving Home.mid\n",
      "Parsing ./midi_songs/Rock And Roll Music.mid\n",
      "Parsing ./midi_songs/Taxman.mid\n",
      "Parsing ./midi_songs/Octopuss Garden.mid\n",
      "Parsing ./midi_songs/Within You Without You.mid\n",
      "Parsing ./midi_songs/When I'm 64.mid\n",
      "Parsing ./midi_songs/Words Of Love.mid\n",
      "Parsing ./midi_songs/Polythene Pam.mid\n",
      "Parsing ./midi_songs/With A Little Help From My Friends.mid\n",
      "Parsing ./midi_songs/Paperback Writer.mid\n",
      "Parsing ./midi_songs/Why Don't We Do It In The Road.mid\n",
      "Parsing ./midi_songs/Tomorrow Never Knows.mid\n",
      "Parsing ./midi_songs/Tell Me Why.mid\n",
      "Parsing ./midi_songs/There's A Place.mid\n",
      "Parsing ./midi_songs/Something.mid\n",
      "Parsing ./midi_songs/Think For Yourself.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/music21/midi/translate.py:874: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=3, channel=None, data=b'bl\\x84ser  '>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/music21/midi/translate.py:874: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'fl\\x84che  '>; getting generic Instrument\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ./midi_songs/Ob La_Di_Ob_La_Da.mid\n",
      "Parsing ./midi_songs/Slow Down.mid\n",
      "Parsing ./midi_songs/Tell Me What You See.mid\n",
      "Parsing ./midi_songs/Till There Was You.mid\n",
      "Parsing ./midi_songs/Yellow Submarine.mid\n",
      "Parsing ./midi_songs/Michelle.mid\n",
      "Parsing ./midi_songs/Oh Darling.mid\n",
      "Parsing ./midi_songs/Misery.mid\n",
      "Parsing ./midi_songs/She Loves You.mid\n",
      "Parsing ./midi_songs/She Said She Said.mid\n",
      "Parsing ./midi_songs/You've Got To Hide Your Love Away.mid\n",
      "Parsing ./midi_songs/Yes It Is.mid\n",
      "Parsing ./midi_songs/Roll Over Beethoven.mid\n",
      "Parsing ./midi_songs/Twist And Shout.mid\n",
      "Parsing ./midi_songs/You Can't Do That.mid\n",
      "Parsing ./midi_songs/Yesterday.mid\n",
      "Parsing ./midi_songs/When I Get Home.mid\n",
      "Parsing ./midi_songs/We Can Work It Out.mid\n",
      "Parsing ./midi_songs/You Never Give Me Your Money.mid\n",
      "Parsing ./midi_songs/The Fool On The Hill.mid\n",
      "Parsing ./midi_songs/Long Tall Sally.mid\n",
      "Parsing ./midi_songs/Thank You_Girl.mid\n",
      "Parsing ./midi_songs/The Night Before.mid\n",
      "Parsing ./midi_songs/Your Mother Should Know.mid\n",
      "Parsing ./midi_songs/The Word.mid\n",
      "Parsing ./midi_songs/You're Going To Lose That Girl.mid\n",
      "Parsing ./midi_songs/She's A Woman.mid\n",
      "Parsing ./midi_songs/Strawberry Fields Forever.mid\n",
      "Parsing ./midi_songs/Ticket To Ride.mid\n",
      "Parsing ./midi_songs/While My Guitar Gently Weeps.mid\n",
      "Parsing ./midi_songs/This Boy.mid\n",
      "Parsing ./midi_songs/You Like Me Too Much.mid\n",
      "Parsing ./midi_songs/You Won't See Me.mid\n",
      "Parsing ./midi_songs/Things We Said Today.mid\n",
      "Parsing ./midi_songs/You Really Got A Hold On Me.mid\n",
      "Parsing ./midi_songs/You Know My Name.mid\n",
      "Parsing ./midi_songs/Two Of Us.mid\n",
      "Parsing ./midi_songs/A Day In The Life.mid\n",
      "Parsing ./midi_songs/Yer Blues.mid\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Extract all notes and chords from MIDI files in a directory\n",
    "\"\"\"\n",
    "\n",
    "import glob\n",
    "from music21 import converter, instrument, note, chord\n",
    "\n",
    "# Initialize lists to store notes, rests, and other data\n",
    "notes = []\n",
    "rests = []\n",
    "notes_without_rests = []\n",
    "rest_to_duration = {}\n",
    "\n",
    "# Use glob to read MIDI files from the specified path:\n",
    "# \"./\"               - Current directory\n",
    "# \"midi_songs/\"      - Folder named midi_songs\n",
    "# \"*.mid\"            - All files with a .mid extension\n",
    "# Notes are the musical pitches; this script reads notes from MIDI files into a list\n",
    "\n",
    "for file in glob.glob(\"./midi_songs/*.mid\"):  # Read all MIDI files from the folder\n",
    "    # Parse the MIDI file using music21\n",
    "    midi = converter.parse(file)\n",
    "\n",
    "    print(f\"Parsing {file}\")\n",
    "\n",
    "    notes_to_parse = None\n",
    "\n",
    "    try:  # If the MIDI has instrument parts, select the first one\n",
    "        s2 = instrument.partitionByInstrument(midi)\n",
    "        notes_to_parse = s2.parts[0].recurse()\n",
    "    except:  # If no instrument parts, get notes directly\n",
    "        notes_to_parse = midi.flat.notes\n",
    "\n",
    "    for element in notes_to_parse:\n",
    "        # If the element is a Note, get its pitch\n",
    "        if isinstance(element, note.Note):\n",
    "            notes.append(str(element.pitch))\n",
    "            notes_without_rests.append(str(element.pitch))\n",
    "        # If the element is a Rest, get its name and duration\n",
    "        elif isinstance(element, note.Rest):\n",
    "            notes.append(str(element.fullName))\n",
    "            rests.append(str(element.fullName))\n",
    "            rest_to_duration[element.fullName] = element.duration.quarterLength\n",
    "        # If the element is a Chord, get its pitches as integers for easier processing\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            pitches = '.'.join(str(n) for n in element.normalOrder)\n",
    "            notes.append(pitches)\n",
    "            notes_without_rests.append(pitches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 準備神經網絡使用的輸入輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Explanation of Variables =====\n",
      "\n",
      "notes: A list storing all notes in the sheet music as strings.\n",
      "Total number of notes (including rests): 63844\n",
      "Total number of notes (excluding rests): 234\n",
      "Total number of unique note/rest names: 285\n",
      "Total number of unique rest names: 51\n",
      "Unique note names: ['0', '0.1', '0.2', '0.2.4.7', '0.2.5', '0.2.7', '0.3', '0.3.5', '0.4', '0.4.7', '0.5', '1', '1.2', '1.2.4', '1.2.6', '1.3', '1.3.7', '1.4', '1.4.6.9', '1.4.7', '1.4.7.9', '1.4.8', '1.5', '1.5.7', '1.5.8', '1.6', '1.7', '10', '10.0.2.5', '10.0.4', '10.0.4.5', '10.0.5', '10.1', '10.1.2.6', '10.1.4', '10.1.5', '10.11', '10.2', '10.2.5', '10.3', '11', '11.0', '11.0.3', '11.0.4.7', '11.1', '11.2', '11.2.4', '11.2.4.6', '11.2.4.7', '11.2.5', '11.2.5.7', '11.2.6', '11.3', '11.3.6', '11.4', '2', '2.3', '2.3.4', '2.4', '2.4.6.8.11', '2.4.6.9', '2.4.7.10', '2.5', '2.5.7', '2.5.7.10', '2.5.7.9', '2.5.8', '2.5.9', '2.6', '2.6.10', '2.6.9', '2.7', '2.8', '3', '3.4', '3.4.7.11', '3.5', '3.5.7', '3.5.7.9', '3.5.7.9.0', '3.5.9', '3.6', '3.6.9.11', '3.7', '3.8', '3.9', '4', '4.10', '4.5', '4.5.9.0', '4.6', '4.6.9.11', '4.7', '4.7.10.0', '4.7.11', '4.7.9', '4.7.9.0', '4.7.9.11', '4.8', '4.8.11', '4.9', '5', '5.10', '5.11', '5.6', '5.6.7.8', '5.6.8', '5.7', '5.7.0', '5.7.11', '5.7.9', '5.8', '5.9', '5.9.0', '6', '6.10', '6.11', '6.7', '6.8', '6.9', '6.9.0', '6.9.0.2', '6.9.1', '6.9.11.2', '7', '7.0', '7.10', '7.10.0', '7.10.1.3', '7.10.2', '7.11', '7.11.2', '7.9', '7.9.0.3', '7.9.11', '7.9.11.1.4', '7.9.11.2.4', '7.9.2', '8', '8.0', '8.1', '8.10', '8.11', '8.11.2', '8.11.2.4', '8.11.3', '8.9', '8.9.1.4', '8.9.11', '9', '9.0', '9.0.2.4', '9.0.2.5', '9.0.3', '9.0.3.5', '9.0.4', '9.1', '9.1.4', '9.10', '9.11', '9.11.1', '9.11.1.3', '9.11.2', '9.11.3', '9.2', 'A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'B-1', 'B-2', 'B-3', 'B-4', 'B-5', 'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'C#2', 'C#3', 'C#4', 'C#5', 'C#6', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'E-2', 'E-3', 'E-4', 'E-5', 'E-6', 'E1', 'E2', 'E3', 'E4', 'E5', 'E6', 'F#1', 'F#2', 'F#3', 'F#4', 'F#5', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'G#1', 'G#2', 'G#3', 'G#4', 'G#5', 'G#6', 'G1', 'G2', 'G3', 'G4', 'G5', 'G6']\n",
      "Mapping of note names to integers: {'0': 0, '0.1': 1, '0.2': 2, '0.2.4.7': 3, '0.2.5': 4, '0.2.7': 5, '0.3': 6, '0.3.5': 7, '0.4': 8, '0.4.7': 9, '0.5': 10, '1': 11, '1.2': 12, '1.2.4': 13, '1.2.6': 14, '1.3': 15, '1.3.7': 16, '1.4': 17, '1.4.6.9': 18, '1.4.7': 19, '1.4.7.9': 20, '1.4.8': 21, '1.5': 22, '1.5.7': 23, '1.5.8': 24, '1.6': 25, '1.7': 26, '10': 27, '10.0.2.5': 28, '10.0.4': 29, '10.0.4.5': 30, '10.0.5': 31, '10.1': 32, '10.1.2.6': 33, '10.1.4': 34, '10.1.5': 35, '10.11': 36, '10.2': 37, '10.2.5': 38, '10.3': 39, '11': 40, '11.0': 41, '11.0.3': 42, '11.0.4.7': 43, '11.1': 44, '11.2': 45, '11.2.4': 46, '11.2.4.6': 47, '11.2.4.7': 48, '11.2.5': 49, '11.2.5.7': 50, '11.2.6': 51, '11.3': 52, '11.3.6': 53, '11.4': 54, '16th Rest': 55, '16th Triplet (1/6 QL) Rest': 56, '2': 57, '2.3': 58, '2.3.4': 59, '2.4': 60, '2.4.6.8.11': 61, '2.4.6.9': 62, '2.4.7.10': 63, '2.5': 64, '2.5.7': 65, '2.5.7.10': 66, '2.5.7.9': 67, '2.5.8': 68, '2.5.9': 69, '2.6': 70, '2.6.10': 71, '2.6.9': 72, '2.7': 73, '2.8': 74, '3': 75, '3.4': 76, '3.4.7.11': 77, '3.5': 78, '3.5.7': 79, '3.5.7.9': 80, '3.5.7.9.0': 81, '3.5.9': 82, '3.6': 83, '3.6.9.11': 84, '3.7': 85, '3.8': 86, '3.9': 87, '32nd Triplet (1/12 QL) Rest': 88, '4': 89, '4.10': 90, '4.5': 91, '4.5.9.0': 92, '4.6': 93, '4.6.9.11': 94, '4.7': 95, '4.7.10.0': 96, '4.7.11': 97, '4.7.9': 98, '4.7.9.0': 99, '4.7.9.11': 100, '4.8': 101, '4.8.11': 102, '4.9': 103, '5': 104, '5.10': 105, '5.11': 106, '5.6': 107, '5.6.7.8': 108, '5.6.8': 109, '5.7': 110, '5.7.0': 111, '5.7.11': 112, '5.7.9': 113, '5.8': 114, '5.9': 115, '5.9.0': 116, '6': 117, '6.10': 118, '6.11': 119, '6.7': 120, '6.8': 121, '6.9': 122, '6.9.0': 123, '6.9.0.2': 124, '6.9.1': 125, '6.9.11.2': 126, '7': 127, '7.0': 128, '7.10': 129, '7.10.0': 130, '7.10.1.3': 131, '7.10.2': 132, '7.11': 133, '7.11.2': 134, '7.9': 135, '7.9.0.3': 136, '7.9.11': 137, '7.9.11.1.4': 138, '7.9.11.2.4': 139, '7.9.2': 140, '8': 141, '8.0': 142, '8.1': 143, '8.10': 144, '8.11': 145, '8.11.2': 146, '8.11.2.4': 147, '8.11.3': 148, '8.9': 149, '8.9.1.4': 150, '8.9.11': 151, '9': 152, '9.0': 153, '9.0.2.4': 154, '9.0.2.5': 155, '9.0.3': 156, '9.0.3.5': 157, '9.0.4': 158, '9.1': 159, '9.1.4': 160, '9.10': 161, '9.11': 162, '9.11.1': 163, '9.11.1.3': 164, '9.11.2': 165, '9.11.3': 166, '9.2': 167, 'A1': 168, 'A2': 169, 'A3': 170, 'A4': 171, 'A5': 172, 'A6': 173, 'B-1': 174, 'B-2': 175, 'B-3': 176, 'B-4': 177, 'B-5': 178, 'B1': 179, 'B2': 180, 'B3': 181, 'B4': 182, 'B5': 183, 'B6': 184, 'Breve Tuplet of 24/13ths (4 1/3 QL) Rest': 185, 'Breve Tuplet of 24/17ths (5 2/3 QL) Rest': 186, 'C#2': 187, 'C#3': 188, 'C#4': 189, 'C#5': 190, 'C#6': 191, 'C2': 192, 'C3': 193, 'C4': 194, 'C5': 195, 'C6': 196, 'C7': 197, 'D1': 198, 'D2': 199, 'D3': 200, 'D4': 201, 'D5': 202, 'D6': 203, 'Dotted Eighth Rest': 204, 'Dotted Half Rest': 205, 'Dotted Quarter Rest': 206, 'Dotted Whole Rest': 207, 'Double Dotted Half Rest': 208, 'Double Dotted Quarter Rest': 209, 'E-2': 210, 'E-3': 211, 'E-4': 212, 'E-5': 213, 'E-6': 214, 'E1': 215, 'E2': 216, 'E3': 217, 'E4': 218, 'E5': 219, 'E6': 220, 'Eighth Rest': 221, 'Eighth Triplet (1/3 QL) Rest': 222, 'Eighth Tuplet of 6/5ths (5/12 QL) Rest': 223, 'F#1': 224, 'F#2': 225, 'F#3': 226, 'F#4': 227, 'F#5': 228, 'F1': 229, 'F2': 230, 'F3': 231, 'F4': 232, 'F5': 233, 'F6': 234, 'F7': 235, 'G#1': 236, 'G#2': 237, 'G#3': 238, 'G#4': 239, 'G#5': 240, 'G#6': 241, 'G1': 242, 'G2': 243, 'G3': 244, 'G4': 245, 'G5': 246, 'G6': 247, 'Half Rest': 248, 'Half Triplet (1 1/3 QL) Rest': 249, 'Half Tuplet of 12/11ths (1 5/6 QL) Rest': 250, 'Half Tuplet of 12/7ths (1 1/6 QL) Rest': 251, 'Half Tuplet of 24/17ths (1 5/12 QL) Rest': 252, 'Half Tuplet of 24/19ths (1 7/12 QL) Rest': 253, 'Half Tuplet of 24/23rds (1 11/12 QL) Rest': 254, 'Half Tuplet of 6/5ths (1 2/3 QL) Rest': 255, 'Half tied to 16th (2 1/4 total QL) Rest': 256, 'Half tied to Dotted Eighth (2 3/4 total QL) Rest': 257, 'Half tied to Eighth (2 1/2 total QL) Rest': 258, 'Half tied to Quarter tied to 16th (3 1/4 total QL) Rest': 259, 'Quarter Rest': 260, 'Quarter Triplet (2/3 QL) Rest': 261, 'Quarter Tuplet of 12/11ths (11/12 QL) Rest': 262, 'Quarter Tuplet of 12/7ths (7/12 QL) Rest': 263, 'Quarter Tuplet of 6/5ths (5/6 QL) Rest': 264, 'Quarter tied to 16th (1 1/4 total QL) Rest': 265, 'Triple Dotted Half (3 3/4 QL) Rest': 266, 'Whole Rest': 267, 'Whole Triplet (2 2/3 QL) Rest': 268, 'Whole Tuplet of 12/11ths (3 2/3 QL) Rest': 269, 'Whole Tuplet of 12/7ths (2 1/3 QL) Rest': 270, 'Whole Tuplet of 24/13ths (2 1/6 QL) Rest': 271, 'Whole Tuplet of 24/19ths (3 1/6 QL) Rest': 272, 'Whole Tuplet of 48/25ths (2 1/12 QL) Rest': 273, 'Whole Tuplet of 48/29ths (2 5/12 QL) Rest': 274, 'Whole Tuplet of 48/31st (2 7/12 QL) Rest': 275, 'Whole Tuplet of 48/35ths (2 11/12 QL) Rest': 276, 'Whole Tuplet of 6/5ths (3 1/3 QL) Rest': 277, 'Whole tied to 16th (4 1/4 total QL) Rest': 278, 'Whole tied to Dotted Eighth (4 3/4 total QL) Rest': 279, 'Whole tied to Dotted Quarter (5 1/2 total QL) Rest': 280, 'Whole tied to Double Dotted Quarter (5 3/4 total QL) Rest': 281, 'Whole tied to Eighth (4 1/2 total QL) Rest': 282, 'Whole tied to Quarter (5 total QL) Rest': 283, 'Whole tied to Quarter tied to 16th (5 1/4 total QL) Rest': 284}\n",
      "\n",
      "===================\n",
      "\n",
      "Total notes in 'notes': 63844\n",
      "Each 100 notes form one training sample.\n",
      "Total training samples (network_input): 63744, each with 100 integers.\n",
      "Total output samples (network_output): 63744, each representing the next note's integer.\n",
      "\n",
      "===================\n",
      "\n",
      "Notes from position sequence_length-10 to sequence_length: ['G#4', 'Half Rest', 'Dotted Half Rest', 'G#4', 'E5', 'C#5', 'G#4', 'E5', 'G#4', 'G#4']\n",
      "Their corresponding integers: [239, 248, 205, 239, 219, 190, 239, 219, 239, 239]\n",
      "\n",
      "Last 10 integers of network_input[0]: [239, 248, 205, 239, 219, 190, 239, 219, 239, 239]\n",
      "Last 10 integers of network_input[1]: [248, 205, 239, 219, 190, 239, 219, 239, 239, 190]\n",
      "Last 10 integers of network_input[2]: [205, 239, 219, 190, 239, 219, 239, 239, 190, 219]\n",
      "First three integers in network_output: [190, 219, 171]\n",
      "\n",
      "===== Reshaped Data =====\n",
      "\n",
      "Shape of normalized_input: (63744, 100, 1)\n",
      "Shape of network_output: (63744, 285)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Prepare input and output for the neural network\n",
    "\"\"\"\n",
    "\n",
    "import numpy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Get the number of unique note names (including rests)\n",
    "n_vocab = len(set(notes))\n",
    "# Sorted list of unique note names (including rests)\n",
    "pitch_and_rest = sorted(set(item for item in notes))\n",
    "# Sorted list of unique note names (excluding rests)\n",
    "pitchnames = sorted(set(item for item in notes_without_rests))\n",
    "# Sorted list of unique rest names\n",
    "restnames = sorted(set(item for item in rests))\n",
    "# Create a dictionary mapping each note/rest to an integer for training\n",
    "note_to_int = {note: number for number, note in enumerate(pitch_and_rest)}\n",
    "\n",
    "\"\"\"\n",
    "# Alternative: Map notes and rests separately\n",
    "note_to_int = {note: number for number, note in enumerate(pitchnames)}\n",
    "note_to_int.update({rest: number + len(pitchnames) for number, rest in enumerate(restnames)})\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n===== Explanation of Variables =====\\n\")\n",
    "print(\"notes: A list storing all notes in the sheet music as strings.\")\n",
    "print(f\"Total number of notes (including rests): {len(notes)}\")\n",
    "print(f\"Total number of notes (excluding rests): {len(pitchnames)}\")\n",
    "print(f\"Total number of unique note/rest names: {n_vocab}\")\n",
    "print(f\"Total number of unique rest names: {len(set(rests))}\")\n",
    "print(f\"Unique note names: {pitchnames}\")\n",
    "print(f\"Mapping of note names to integers: {note_to_int}\")\n",
    "\n",
    "# Length of the input sequence for training (number of notes per sequence)\n",
    "sequence_length = 100\n",
    "\n",
    "# Initialize input and output sequences for training\n",
    "network_input = []\n",
    "network_output = []\n",
    "\n",
    "# ===== Create input sequences and corresponding outputs from the notes =====\n",
    "for i in range(0, len(notes) - sequence_length, 1):\n",
    "    sequence_in = notes[i:i + sequence_length]  # Input sequence of notes\n",
    "    sequence_out = notes[i + sequence_length]  # The next note as output\n",
    "    \n",
    "    # Convert notes in the input sequence to their corresponding integer values\n",
    "    network_input.append([note_to_int[char] for char in sequence_in])\n",
    "    # Convert the output note to its corresponding integer value\n",
    "    network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "print(\"\\n===================\\n\")\n",
    "print(f\"Total notes in 'notes': {len(notes)}\")\n",
    "print(f\"Each {sequence_length} notes form one training sample.\")\n",
    "print(f\"Total training samples (network_input): {len(network_input)}, each with {len(network_input[0])} integers.\")\n",
    "print(f\"Total output samples (network_output): {len(network_output)}, each representing the next note's integer.\")\n",
    "print(\"\\n===================\\n\")\n",
    "print(\"Notes from position sequence_length-10 to sequence_length:\", notes[sequence_length-10:sequence_length])\n",
    "print(\"Their corresponding integers:\", [note_to_int[char] for char in notes[sequence_length-10:sequence_length]])\n",
    "print(\"\")\n",
    "print(f\"Last 10 integers of network_input[0]: {network_input[0][sequence_length-10:sequence_length]}\")\n",
    "print(f\"Last 10 integers of network_input[1]: {network_input[1][sequence_length-10:sequence_length]}\")\n",
    "print(f\"Last 10 integers of network_input[2]: {network_input[2][sequence_length-10:sequence_length]}\")\n",
    "print(\"First three integers in network_output:\", network_output[0:3])\n",
    "\n",
    "# Total number of training patterns\n",
    "n_patterns = len(network_input)\n",
    "\n",
    "# ===== Reshape input to be compatible with LSTM layers =====\n",
    "normalized_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "\n",
    "# Normalize input values\n",
    "normalized_input = normalized_input / float(n_vocab)\n",
    "\n",
    "# Convert output to a one-hot encoded format suitable for categorical_crossentropy\n",
    "network_output = to_categorical(network_output, n_vocab)\n",
    "\n",
    "print(\"\\n===== Reshaped Data =====\\n\")\n",
    "print(\"Shape of normalized_input:\", normalized_input.shape)\n",
    "print(\"Shape of network_output:\", network_output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 創建神經網絡的結構 \n",
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733151509.720012  208020 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46872 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:c9:00.0, compute capability: 8.6\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,052,672</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">285</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,245</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">285</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │     \u001b[38;5;34m1,052,672\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │     \u001b[38;5;34m2,099,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m2,099,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m285\u001b[0m)            │        \u001b[38;5;34m73,245\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m285\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,458,717</span> (20.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,458,717\u001b[0m (20.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,457,181</span> (20.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,457,181\u001b[0m (20.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> (6.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,536\u001b[0m (6.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Define the Neural Network Architecture\n",
    "\"\"\"\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, BatchNormalization as BatchNorm, Dropout, Dense, Activation\n",
    "\n",
    "# Reference for LSTM parameters:\n",
    "# https://huhuhang.com/post/machine-learning/lstm-return-sequences-state\n",
    "\n",
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first LSTM layer with 512 units\n",
    "model.add(LSTM(\n",
    "    512,\n",
    "    input_shape=(normalized_input.shape[1], normalized_input.shape[2]),\n",
    "    recurrent_dropout=0.1,  # Dropout applied to recurrent connections\n",
    "    return_sequences=True   # Ensure the output is a sequence for stacking\n",
    "))\n",
    "\n",
    "# Add the second LSTM layer with 512 units\n",
    "model.add(LSTM(\n",
    "    512,\n",
    "    return_sequences=True,  # Continue outputting sequences\n",
    "    recurrent_dropout=0.1\n",
    "))\n",
    "\n",
    "# Add the third LSTM layer with 512 units (no sequences returned)\n",
    "model.add(LSTM(512))\n",
    "\n",
    "# Add a Batch Normalization layer to normalize activations\n",
    "model.add(BatchNorm())\n",
    "\n",
    "# Add a Dropout layer to prevent overfitting\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# Add a Dense (fully connected) layer with 256 units and ReLU activation\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Add another Batch Normalization layer\n",
    "model.add(BatchNorm())\n",
    "\n",
    "# Add another Dropout layer\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# Add the final Dense layer with `n_vocab` units and softmax activation\n",
    "# This maps the output to probabilities for each note\n",
    "model.add(Dense(n_vocab))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compile the model with categorical cross-entropy loss and RMSprop optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練神經網絡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733151514.403303  208434 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 4.1141\n",
      "Epoch 1: loss improved from inf to 3.84187, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 124ms/step - loss: 4.1136\n",
      "Epoch 2/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 3.4879\n",
      "Epoch 2: loss improved from 3.84187 to 3.45177, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 128ms/step - loss: 3.4878\n",
      "Epoch 3/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 3.3172\n",
      "Epoch 3: loss improved from 3.45177 to 3.26850, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 125ms/step - loss: 3.3171\n",
      "Epoch 4/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 3.0970\n",
      "Epoch 4: loss improved from 3.26850 to 3.05645, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 125ms/step - loss: 3.0969\n",
      "Epoch 5/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 2.8590\n",
      "Epoch 5: loss improved from 3.05645 to 2.80961, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 126ms/step - loss: 2.8589\n",
      "Epoch 6/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 2.6061\n",
      "Epoch 6: loss improved from 2.80961 to 2.56343, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 125ms/step - loss: 2.6060\n",
      "Epoch 7/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 2.3781\n",
      "Epoch 7: loss improved from 2.56343 to 2.34399, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 125ms/step - loss: 2.3781\n",
      "Epoch 8/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 2.1628\n",
      "Epoch 8: loss improved from 2.34399 to 2.15022, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 126ms/step - loss: 2.1628\n",
      "Epoch 9/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 1.9722\n",
      "Epoch 9: loss improved from 2.15022 to 1.97072, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 124ms/step - loss: 1.9722\n",
      "Epoch 10/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 1.8209\n",
      "Epoch 10: loss improved from 1.97072 to 1.82323, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 126ms/step - loss: 1.8209\n",
      "Epoch 11/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 1.6782\n",
      "Epoch 11: loss improved from 1.82323 to 1.68296, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 125ms/step - loss: 1.6782\n",
      "Epoch 12/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 1.5544\n",
      "Epoch 12: loss improved from 1.68296 to 1.55805, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 125ms/step - loss: 1.5544\n",
      "Epoch 13/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 1.4240\n",
      "Epoch 13: loss improved from 1.55805 to 1.43743, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 126ms/step - loss: 1.4240\n",
      "Epoch 14/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 1.3062\n",
      "Epoch 14: loss improved from 1.43743 to 1.33024, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 126ms/step - loss: 1.3063\n",
      "Epoch 15/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 1.2054\n",
      "Epoch 15: loss improved from 1.33024 to 1.22715, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 125ms/step - loss: 1.2054\n",
      "Epoch 16/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 1.1130\n",
      "Epoch 16: loss improved from 1.22715 to 1.12675, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 125ms/step - loss: 1.1130\n",
      "Epoch 17/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 1.0081\n",
      "Epoch 17: loss improved from 1.12675 to 1.03665, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 126ms/step - loss: 1.0081\n",
      "Epoch 18/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.9236\n",
      "Epoch 18: loss improved from 1.03665 to 0.95488, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 124ms/step - loss: 0.9237\n",
      "Epoch 19/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.8488\n",
      "Epoch 19: loss improved from 0.95488 to 0.88294, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 126ms/step - loss: 0.8488\n",
      "Epoch 20/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.7676\n",
      "Epoch 20: loss improved from 0.88294 to 0.81311, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 126ms/step - loss: 0.7677\n",
      "Epoch 21/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.7115\n",
      "Epoch 21: loss improved from 0.81311 to 0.75000, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 125ms/step - loss: 0.7116\n",
      "Epoch 22/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.6522\n",
      "Epoch 22: loss improved from 0.75000 to 0.68796, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 125ms/step - loss: 0.6523\n",
      "Epoch 23/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.5893\n",
      "Epoch 23: loss improved from 0.68796 to 0.63817, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 125ms/step - loss: 0.5894\n",
      "Epoch 24/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.5478\n",
      "Epoch 24: loss improved from 0.63817 to 0.58413, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 126ms/step - loss: 0.5479\n",
      "Epoch 25/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.4971\n",
      "Epoch 25: loss improved from 0.58413 to 0.53772, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 126ms/step - loss: 0.4972\n",
      "Epoch 26/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.4613\n",
      "Epoch 26: loss improved from 0.53772 to 0.50086, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 124ms/step - loss: 0.4614\n",
      "Epoch 27/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.4360\n",
      "Epoch 27: loss improved from 0.50086 to 0.46654, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 126ms/step - loss: 0.4361\n",
      "Epoch 28/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.4045\n",
      "Epoch 28: loss improved from 0.46654 to 0.43245, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 126ms/step - loss: 0.4046\n",
      "Epoch 29/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.3820\n",
      "Epoch 29: loss improved from 0.43245 to 0.41228, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 126ms/step - loss: 0.3821\n",
      "Epoch 30/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.3549\n",
      "Epoch 30: loss improved from 0.41228 to 0.38084, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 124ms/step - loss: 0.3550\n",
      "Epoch 31/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.3274\n",
      "Epoch 31: loss improved from 0.38084 to 0.35989, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 125ms/step - loss: 0.3275\n",
      "Epoch 32/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.3083\n",
      "Epoch 32: loss improved from 0.35989 to 0.33946, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 125ms/step - loss: 0.3084\n",
      "Epoch 33/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.2908\n",
      "Epoch 33: loss improved from 0.33946 to 0.31602, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 123ms/step - loss: 0.2908\n",
      "Epoch 34/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.2734\n",
      "Epoch 34: loss improved from 0.31602 to 0.29895, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 123ms/step - loss: 0.2735\n",
      "Epoch 35/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.2639\n",
      "Epoch 35: loss improved from 0.29895 to 0.28899, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 127ms/step - loss: 0.2640\n",
      "Epoch 36/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.2557\n",
      "Epoch 36: loss improved from 0.28899 to 0.27118, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 131ms/step - loss: 0.2557\n",
      "Epoch 37/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.2370\n",
      "Epoch 37: loss improved from 0.27118 to 0.25469, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 128ms/step - loss: 0.2370\n",
      "Epoch 38/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.2344\n",
      "Epoch 38: loss improved from 0.25469 to 0.25379, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 127ms/step - loss: 0.2345\n",
      "Epoch 39/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.2242\n",
      "Epoch 39: loss improved from 0.25379 to 0.23624, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 126ms/step - loss: 0.2242\n",
      "Epoch 40/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.2085\n",
      "Epoch 40: loss improved from 0.23624 to 0.22755, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 129ms/step - loss: 0.2086\n",
      "Epoch 41/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.1992\n",
      "Epoch 41: loss improved from 0.22755 to 0.22022, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 127ms/step - loss: 0.1993\n",
      "Epoch 42/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.1875\n",
      "Epoch 42: loss improved from 0.22022 to 0.20859, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 127ms/step - loss: 0.1876\n",
      "Epoch 43/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.1874\n",
      "Epoch 43: loss improved from 0.20859 to 0.20355, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 127ms/step - loss: 0.1875\n",
      "Epoch 44/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.1768\n",
      "Epoch 44: loss improved from 0.20355 to 0.19291, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 125ms/step - loss: 0.1768\n",
      "Epoch 45/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.1757\n",
      "Epoch 45: loss improved from 0.19291 to 0.18918, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 126ms/step - loss: 0.1757\n",
      "Epoch 46/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.1639\n",
      "Epoch 46: loss improved from 0.18918 to 0.18054, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 128ms/step - loss: 0.1639\n",
      "Epoch 47/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.1634\n",
      "Epoch 47: loss improved from 0.18054 to 0.17851, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 128ms/step - loss: 0.1634\n",
      "Epoch 48/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.1519\n",
      "Epoch 48: loss improved from 0.17851 to 0.17090, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 128ms/step - loss: 0.1520\n",
      "Epoch 49/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.1489\n",
      "Epoch 49: loss improved from 0.17090 to 0.16659, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 126ms/step - loss: 0.1489\n",
      "Epoch 50/50\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.1490\n",
      "Epoch 50: loss improved from 0.16659 to 0.16419, saving model to best_model.keras\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 135ms/step - loss: 0.1490\n",
      "Training complete! The best model has been saved as 'best_model.keras'.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train the neural network for generating music sequences.\n",
    "\n",
    "This process adjusts the weights of the model based on the provided input\n",
    "and output, enabling it to learn patterns in the musical dataset. Only the best model\n",
    "based on training loss will be saved.\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Define a callback to save the best model based on training loss\n",
    "callbacks = [\n",
    "    # Save only the best model based on minimum loss\n",
    "    ModelCheckpoint(\n",
    "        filepath='best_model.keras',  # Filepath to save the best model in .keras format\n",
    "        monitor='loss',               # Monitor training loss for improvement\n",
    "        save_best_only=True,          # Save only the best model weights\n",
    "        mode='min',                   # Minimize the monitored value (loss)\n",
    "        verbose=1\n",
    "    ),\n",
    "    # Stop training early if the loss stagnates\n",
    "    EarlyStopping(\n",
    "        monitor='loss', \n",
    "        patience=10,                  # Wait for 10 epochs of no improvement\n",
    "        restore_best_weights=True     # Load the best weights when stopping\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    normalized_input,  # Input data\n",
    "    network_output,    # Expected output\n",
    "    epochs=50,         # Total number of training epochs\n",
    "    batch_size=128,    # Size of each training batch\n",
    "    callbacks=callbacks,  # Attach callbacks\n",
    "    verbose=1          # Print progress during training\n",
    ")\n",
    "\n",
    "print(\"Training complete! The best model has been saved as 'best_model.keras'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根據選定的音符起始點，從神經網絡預測下一個音符並生成樂譜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated notes:\n",
      "B2\n",
      "B2\n",
      "A2\n",
      "G2\n",
      "G2\n",
      "G2\n",
      "G2\n",
      "A2\n",
      "B2\n",
      "B2\n",
      "B2\n",
      "B2\n",
      "A2\n",
      "G2\n",
      "G2\n",
      "G2\n",
      "G2\n",
      "A2\n",
      "B2\n",
      "B2\n",
      "B2\n",
      "B2\n",
      "E2\n",
      "F#2\n",
      "G2\n",
      "E2\n",
      "A2\n",
      "G2\n",
      "F#2\n",
      "E2\n",
      "D3\n",
      "D3\n",
      "A2\n",
      "B2\n",
      "D3\n",
      "B2\n",
      "G2\n",
      "A2\n",
      "Double Dotted Half Rest\n",
      "D3\n",
      "A2\n",
      "B2\n",
      "D3\n",
      "B2\n",
      "G2\n",
      "A2\n",
      "A2\n",
      "A2\n",
      "C#3\n",
      "E3\n",
      "F#3\n",
      "E3\n",
      "C#3\n",
      "D3\n",
      "A2\n",
      "B2\n",
      "D3\n",
      "B2\n",
      "G2\n",
      "A2\n",
      "A2\n",
      "A2\n",
      "C#3\n",
      "E3\n",
      "F#3\n",
      "E3\n",
      "C#3\n",
      "D3\n",
      "A2\n",
      "B2\n",
      "D3\n",
      "B2\n",
      "G2\n",
      "A2\n",
      "A2\n",
      "A2\n",
      "C#3\n",
      "E3\n",
      "F#3\n",
      "E3\n",
      "C#3\n",
      "D3\n",
      "A2\n",
      "B2\n",
      "D3\n",
      "B2\n",
      "G2\n",
      "A2\n",
      "A2\n",
      "A2\n",
      "C#3\n",
      "E3\n",
      "F#3\n",
      "E3\n",
      "C#3\n",
      "D3\n",
      "A2\n",
      "B2\n",
      "D3\n",
      "B2\n",
      "G2\n",
      "A2\n",
      "A2\n",
      "A2\n",
      "C#3\n",
      "E3\n",
      "F#3\n",
      "E3\n",
      "C#3\n",
      "D3\n",
      "A2\n",
      "B2\n",
      "D3\n",
      "B2\n",
      "G2\n",
      "A2\n",
      "A2\n",
      "A2\n",
      "C#3\n",
      "E3\n",
      "F#3\n",
      "E3\n",
      "C#3\n",
      "D3\n",
      "A2\n",
      "B2\n",
      "D3\n",
      "B2\n",
      "G2\n",
      "A2\n",
      "A2\n",
      "A2\n",
      "C#3\n",
      "E3\n",
      "F#3\n",
      "E3\n",
      "C#3\n",
      "D3\n",
      "A2\n",
      "B2\n",
      "D3\n",
      "B2\n",
      "G2\n",
      "A2\n",
      "A2\n",
      "A2\n",
      "C#3\n",
      "E3\n",
      "F#3\n",
      "E3\n",
      "C#3\n",
      "D3\n",
      "A2\n",
      "B2\n",
      "D3\n",
      "B2\n",
      "G2\n",
      "A2\n",
      "A2\n",
      "A2\n",
      "C#3\n",
      "E3\n",
      "F#3\n",
      "E3\n",
      "C#3\n",
      "D3\n",
      "A2\n",
      "B2\n",
      "D3\n",
      "B2\n",
      "G2\n",
      "A2\n",
      "A2\n",
      "A2\n",
      "C#3\n",
      "E3\n",
      "F#3\n",
      "E3\n",
      "C#3\n",
      "D3\n",
      "A2\n",
      "B2\n",
      "D3\n",
      "B2\n",
      "G2\n",
      "A2\n",
      "A2\n",
      "A2\n",
      "C#3\n",
      "E3\n",
      "F#3\n",
      "E3\n",
      "C#3\n",
      "D3\n",
      "A2\n",
      "B2\n",
      "D3\n",
      "B2\n",
      "G2\n",
      "A2\n",
      "A2\n",
      "A2\n",
      "C#3\n",
      "E3\n",
      "F#3\n",
      "E3\n",
      "C#3\n",
      "D3\n",
      "A2\n",
      "B2\n",
      "D3\n",
      "B2\n",
      "G2\n",
      "A2\n",
      "A2\n",
      "A2\n",
      "C#3\n",
      "E3\n",
      "F#3\n",
      "E3\n",
      "C#3\n",
      "D3\n",
      "A2\n",
      "B2\n",
      "D3\n",
      "B2\n",
      "G2\n",
      "A2\n",
      "A2\n",
      "A2\n",
      "C#3\n",
      "E3\n",
      "F#3\n",
      "E3\n",
      "C#3\n",
      "D3\n",
      "A2\n",
      "B2\n",
      "D3\n",
      "B2\n",
      "G2\n",
      "A2\n",
      "A2\n",
      "A2\n",
      "C#3\n",
      "E3\n",
      "F#3\n",
      "E3\n",
      "C#3\n",
      "D3\n",
      "A2\n",
      "B2\n",
      "D3\n",
      "B2\n",
      "G2\n",
      "A2\n",
      "A2\n",
      "A2\n",
      "C#3\n",
      "E3\n",
      "F#3\n",
      "E3\n",
      "C#3\n",
      "D3\n",
      "A2\n",
      "B2\n",
      "D3\n",
      "B2\n",
      "G2\n",
      "A2\n",
      "A2\n",
      "A2\n",
      "C#3\n",
      "E3\n",
      "F#3\n",
      "E3\n",
      "C#3\n",
      "D3\n",
      "A2\n",
      "B2\n",
      "D3\n",
      "B2\n",
      "G2\n",
      "A2\n",
      "A2\n",
      "A2\n",
      "C#3\n",
      "E3\n",
      "F#3\n",
      "E3\n",
      "C#3\n",
      "D3\n",
      "A2\n",
      "B2\n",
      "D3\n",
      "B2\n",
      "G2\n",
      "A2\n",
      "A2\n",
      "A2\n",
      "C#3\n",
      "E3\n",
      "F#3\n",
      "E3\n",
      "C#3\n",
      "D3\n",
      "A2\n",
      "B2\n",
      "D3\n",
      "B2\n",
      "G2\n",
      "A2\n",
      "A2\n",
      "A2\n",
      "C#3\n",
      "E3\n",
      "F#3\n",
      "E3\n",
      "C#3\n",
      "D3\n",
      "A2\n",
      "B2\n",
      "D3\n",
      "B2\n",
      "G2\n",
      "A2\n",
      "A2\n",
      "A2\n",
      "C#3\n",
      "E3\n",
      "F#3\n",
      "E3\n",
      "C#3\n",
      "D3\n",
      "A2\n",
      "B2\n",
      "D3\n",
      "B2\n",
      "G2\n",
      "A2\n",
      "A2\n",
      "A2\n",
      "C#3\n",
      "E3\n",
      "F#3\n",
      "E3\n",
      "C#3\n",
      "D3\n",
      "A2\n",
      "B2\n",
      "D3\n",
      "B2\n",
      "G2\n",
      "A2\n",
      "A2\n",
      "A2\n",
      "C#3\n",
      "E3\n",
      "F#3\n",
      "E3\n",
      "C#3\n",
      "D3\n",
      "A2\n",
      "B2\n",
      "D3\n",
      "B2\n",
      "G2\n",
      "A2\n",
      "A2\n",
      "A2\n",
      "C#3\n",
      "E3\n",
      "F#3\n",
      "E3\n",
      "C#3\n",
      "D3\n",
      "A2\n",
      "B2\n",
      "D3\n",
      "B2\n",
      "G2\n",
      "A2\n",
      "A2\n",
      "A2\n",
      "C#3\n",
      "E3\n",
      "F#3\n",
      "E3\n",
      "C#3\n",
      "D3\n",
      "A2\n",
      "B2\n",
      "D3\n",
      "B2\n",
      "G2\n",
      "A2\n",
      "A2\n",
      "A2\n",
      "C#3\n",
      "E3\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate Notes Using the Neural Network\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "# Randomly select a starting sequence from the training data\n",
    "start = np.random.randint(0, len(network_input) - 1)\n",
    "pattern = network_input[start]  # A sequence of length `sequence_length` as the prediction starting point\n",
    "\n",
    "# Create a dictionary to map integers back to notes\n",
    "int_to_note = {number: note for number, note in enumerate(pitch_and_rest)}\n",
    "\n",
    "# Store the generated notes\n",
    "prediction_output = []\n",
    "\n",
    "print(\"Generated notes:\")\n",
    "\n",
    "# Generate 100 notes (adjust range to generate more or fewer notes)\n",
    "for note_index in range(400):\n",
    "    # Reshape the pattern to the format expected by the model\n",
    "    prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    prediction_input = prediction_input / float(n_vocab)  # Normalize input data\n",
    "\n",
    "    # Predict the probabilities of the next note\n",
    "    prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "    # Select the note with the highest probability\n",
    "    index = np.argmax(prediction)\n",
    "\n",
    "    # Map the integer back to the corresponding note\n",
    "    result = int_to_note[index]\n",
    "    print(result)\n",
    "\n",
    "    # Append the generated note to the output\n",
    "    prediction_output.append(result)\n",
    "\n",
    "    # Slide the prediction window: append the new note and drop the oldest one\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將預測的輸出轉換為音符，並從音符中創建一個MIDI文件 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LSTM_generated_music_with_rests.mid'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Convert Predicted Outputs into Notes and Create a MIDI File\n",
    "\"\"\"\n",
    "\n",
    "from music21 import stream, note, chord, instrument\n",
    "\n",
    "offset = 0  # Time offset between notes\n",
    "output_notes = []  # List to store the generated musical elements\n",
    "\n",
    "# Create note, chord, or rest objects based on the model's generated output\n",
    "for element in prediction_output:\n",
    "    # If the element represents a chord (e.g., \"60.64.67\")\n",
    "    if ('.' in element) or element.isdigit():\n",
    "        notes_in_chord = element.split('.')\n",
    "        notes = []\n",
    "        for current_note in notes_in_chord:\n",
    "            try:\n",
    "                new_note = note.Note(int(current_note))  # Convert to a note object\n",
    "                new_note.storedInstrument = instrument.Piano()  # Assign an instrument\n",
    "                notes.append(new_note)\n",
    "            except ValueError:\n",
    "                pass  # Skip invalid notes\n",
    "        new_chord = chord.Chord(notes)  # Create a chord from the notes\n",
    "        new_chord.offset = offset  # Set the time offset\n",
    "        output_notes.append(new_chord)\n",
    "\n",
    "    # If the element represents a single note (e.g., \"C4\")\n",
    "    elif element in pitchnames:\n",
    "        new_note = note.Note(element)\n",
    "        new_note.offset = offset\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        output_notes.append(new_note)\n",
    "\n",
    "    # If the element represents a rest\n",
    "    elif element in restnames:\n",
    "        # Convert rest representation to duration if necessary\n",
    "        new_rest = note.Rest()\n",
    "        new_rest.quarterLength = rest_to_duration[element]  # Map rest name to duration\n",
    "        new_rest.offset = offset\n",
    "        new_rest.storedInstrument = instrument.Piano()\n",
    "        output_notes.append(new_rest)\n",
    "\n",
    "    # Increment the offset for the next musical element\n",
    "    offset += 0.5\n",
    "\n",
    "# Create a music21 Stream object to hold the notes, chords, and rests\n",
    "midi_stream = stream.Stream(output_notes)\n",
    "\n",
    "# Write the Stream to a MIDI file\n",
    "midi_stream.write('midi', fp='LSTM_generated_music_with_rests.mid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
