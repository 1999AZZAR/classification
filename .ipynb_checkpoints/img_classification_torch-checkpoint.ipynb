{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expression Classification Model Training with PyTorch\n",
    "\n",
    "This notebook demonstrates how to train a custom expression classification model using PyTorch, with CUDA support for GPU acceleration. The model will classify facial expressions into 7 categories: angry, disgust, fear, happy, neutral, sad, and surprise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install TensorFlow Keras NumPy Matplotlib Seaborn Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "PyTorch version: 2.2.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 23056\n",
      "Number of validation samples: 5765\n",
      "Number of test samples: 7066\n",
      "Number of classes: 7\n",
      "Class indices: {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n",
      "Class weights: tensor([1.0311, 9.4433, 1.0035, 0.5747, 0.8264, 0.8338, 1.2846],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "data_dir = './face-expression-recognition-dataset/images/images'\n",
    "img_height, img_width = 48, 48\n",
    "batch_size = 150\n",
    "num_classes = 7\n",
    "\n",
    "# Define transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((img_height, img_width)),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((img_height, img_width)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=train_transform)\n",
    "test_dataset = datasets.ImageFolder(os.path.join(data_dir, 'validation'), transform=test_transform)\n",
    "\n",
    "# Split train dataset into train and validation\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of validation samples: {len(val_dataset)}\")\n",
    "print(f\"Number of test samples: {len(test_dataset)}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Class indices: {train_dataset.dataset.class_to_idx}\")\n",
    "\n",
    "# Compute class weights\n",
    "targets = torch.tensor(train_dataset.dataset.targets)  # Convert targets to tensor\n",
    "class_counts = torch.bincount(targets)  # Count occurrences of each class\n",
    "total_samples = len(targets)\n",
    "class_weights = torch.tensor([total_samples / (num_classes * count) for count in class_counts], dtype=torch.float32).to(device)\n",
    "print(\"Class weights:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExpressionClassifier(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1024, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ExpressionClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExpressionClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 64)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = ExpressionClassifier().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Device Name: NVIDIA RTX 4000 Ada Generation\n",
      "Device Count: 1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'CUDA Available: {torch.cuda.is_available()}')\n",
    "print(f'Device Name: {torch.cuda.get_device_name(0)}')\n",
    "print(f'Device Count: {torch.cuda.device_count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Train Loss: 1.9096 Acc: 0.1933\n",
      "Val Loss: 1.8322 Acc: 0.2333\n",
      "Epoch 2/100\n",
      "Train Loss: 1.8372 Acc: 0.2414\n",
      "Val Loss: 1.7895 Acc: 0.2635\n",
      "Epoch 3/100\n",
      "Train Loss: 1.8014 Acc: 0.2654\n",
      "Val Loss: 1.7526 Acc: 0.3343\n",
      "Epoch 4/100\n",
      "Train Loss: 1.7517 Acc: 0.3197\n",
      "Val Loss: 1.6790 Acc: 0.3611\n",
      "Epoch 5/100\n",
      "Train Loss: 1.7037 Acc: 0.3387\n",
      "Val Loss: 1.6462 Acc: 0.3665\n",
      "Epoch 6/100\n",
      "Train Loss: 1.6547 Acc: 0.3717\n",
      "Val Loss: 1.5533 Acc: 0.4212\n",
      "Epoch 7/100\n",
      "Train Loss: 1.6221 Acc: 0.3746\n",
      "Val Loss: 1.5222 Acc: 0.4389\n",
      "Epoch 8/100\n",
      "Train Loss: 1.5851 Acc: 0.3883\n",
      "Val Loss: 1.5014 Acc: 0.4461\n",
      "Epoch 9/100\n",
      "Train Loss: 1.5555 Acc: 0.4023\n",
      "Val Loss: 1.4835 Acc: 0.4101\n",
      "Epoch 10/100\n",
      "Train Loss: 1.5244 Acc: 0.4082\n",
      "Val Loss: 1.4706 Acc: 0.4316\n",
      "Epoch 11/100\n",
      "Train Loss: 1.5232 Acc: 0.4142\n",
      "Val Loss: 1.4383 Acc: 0.4413\n",
      "Epoch 12/100\n",
      "Train Loss: 1.5090 Acc: 0.4207\n",
      "Val Loss: 1.4457 Acc: 0.4356\n",
      "Epoch 13/100\n",
      "Train Loss: 1.4885 Acc: 0.4203\n",
      "Val Loss: 1.4151 Acc: 0.4576\n",
      "Epoch 14/100\n",
      "Train Loss: 1.4815 Acc: 0.4228\n",
      "Val Loss: 1.4006 Acc: 0.4637\n",
      "Epoch 15/100\n",
      "Train Loss: 1.4603 Acc: 0.4270\n",
      "Val Loss: 1.4027 Acc: 0.4598\n",
      "Epoch 16/100\n",
      "Train Loss: 1.4530 Acc: 0.4378\n",
      "Val Loss: 1.3938 Acc: 0.4808\n",
      "Epoch 17/100\n",
      "Train Loss: 1.4433 Acc: 0.4407\n",
      "Val Loss: 1.3655 Acc: 0.4784\n",
      "Epoch 18/100\n",
      "Train Loss: 1.4316 Acc: 0.4459\n",
      "Val Loss: 1.3745 Acc: 0.4843\n",
      "Epoch 19/100\n",
      "Train Loss: 1.4171 Acc: 0.4487\n",
      "Val Loss: 1.3708 Acc: 0.4803\n",
      "Epoch 20/100\n",
      "Train Loss: 1.4169 Acc: 0.4452\n",
      "Val Loss: 1.3783 Acc: 0.4838\n",
      "Epoch 21/100\n",
      "Train Loss: 1.4096 Acc: 0.4483\n",
      "Val Loss: 1.3615 Acc: 0.4968\n",
      "Epoch 22/100\n",
      "Train Loss: 1.3985 Acc: 0.4545\n",
      "Val Loss: 1.3418 Acc: 0.4945\n",
      "Epoch 23/100\n",
      "Train Loss: 1.3887 Acc: 0.4596\n",
      "Val Loss: 1.3440 Acc: 0.5051\n",
      "Epoch 24/100\n",
      "Train Loss: 1.3908 Acc: 0.4570\n",
      "Val Loss: 1.3568 Acc: 0.4814\n",
      "Epoch 25/100\n",
      "Train Loss: 1.3758 Acc: 0.4618\n",
      "Val Loss: 1.3542 Acc: 0.4873\n",
      "Epoch 26/100\n",
      "Train Loss: 1.3792 Acc: 0.4635\n",
      "Val Loss: 1.3407 Acc: 0.4827\n",
      "Epoch 27/100\n",
      "Train Loss: 1.3573 Acc: 0.4673\n",
      "Val Loss: 1.3151 Acc: 0.4963\n",
      "Epoch 28/100\n",
      "Train Loss: 1.3584 Acc: 0.4669\n",
      "Val Loss: 1.3332 Acc: 0.4866\n",
      "Epoch 29/100\n",
      "Train Loss: 1.3563 Acc: 0.4679\n",
      "Val Loss: 1.3474 Acc: 0.5074\n",
      "Epoch 30/100\n",
      "Train Loss: 1.3470 Acc: 0.4661\n",
      "Val Loss: 1.3086 Acc: 0.5065\n",
      "Epoch 31/100\n",
      "Train Loss: 1.3422 Acc: 0.4723\n",
      "Val Loss: 1.3049 Acc: 0.4859\n",
      "Epoch 32/100\n",
      "Train Loss: 1.3318 Acc: 0.4686\n",
      "Val Loss: 1.3175 Acc: 0.4900\n",
      "Epoch 33/100\n",
      "Train Loss: 1.3336 Acc: 0.4682\n",
      "Val Loss: 1.3097 Acc: 0.4933\n",
      "Epoch 34/100\n",
      "Train Loss: 1.3257 Acc: 0.4770\n",
      "Val Loss: 1.3076 Acc: 0.5001\n",
      "Epoch 35/100\n",
      "Train Loss: 1.3287 Acc: 0.4761\n",
      "Val Loss: 1.3174 Acc: 0.4952\n",
      "Epoch 36/100\n",
      "Train Loss: 1.3089 Acc: 0.4747\n",
      "Val Loss: 1.3092 Acc: 0.5036\n",
      "Epoch 37/100\n",
      "Train Loss: 1.3081 Acc: 0.4813\n",
      "Val Loss: 1.3101 Acc: 0.5112\n",
      "Epoch 38/100\n",
      "Train Loss: 1.3071 Acc: 0.4791\n",
      "Val Loss: 1.3121 Acc: 0.4796\n",
      "Epoch 39/100\n",
      "Train Loss: 1.3002 Acc: 0.4804\n",
      "Val Loss: 1.2865 Acc: 0.4951\n",
      "Epoch 40/100\n",
      "Train Loss: 1.2948 Acc: 0.4799\n",
      "Val Loss: 1.3071 Acc: 0.4958\n",
      "Epoch 41/100\n",
      "Train Loss: 1.3092 Acc: 0.4778\n",
      "Val Loss: 1.2947 Acc: 0.4982\n",
      "Epoch 42/100\n",
      "Train Loss: 1.3051 Acc: 0.4792\n",
      "Val Loss: 1.3136 Acc: 0.5006\n",
      "Epoch 43/100\n",
      "Train Loss: 1.2975 Acc: 0.4833\n",
      "Val Loss: 1.3352 Acc: 0.5063\n",
      "Epoch 44/100\n",
      "Train Loss: 1.2929 Acc: 0.4839\n",
      "Val Loss: 1.3356 Acc: 0.5082\n",
      "Epoch 45/100\n",
      "Train Loss: 1.2850 Acc: 0.4849\n",
      "Val Loss: 1.2967 Acc: 0.4940\n",
      "Epoch 46/100\n",
      "Train Loss: 1.2879 Acc: 0.4865\n",
      "Val Loss: 1.2874 Acc: 0.5141\n",
      "Epoch 47/100\n",
      "Train Loss: 1.2712 Acc: 0.4904\n",
      "Val Loss: 1.2876 Acc: 0.5022\n",
      "Epoch 48/100\n",
      "Train Loss: 1.2758 Acc: 0.4896\n",
      "Val Loss: 1.3309 Acc: 0.5133\n",
      "Epoch 49/100\n",
      "Train Loss: 1.2649 Acc: 0.4925\n",
      "Val Loss: 1.3063 Acc: 0.5160\n",
      "Epoch 50/100\n",
      "Train Loss: 1.2762 Acc: 0.4934\n",
      "Val Loss: 1.2888 Acc: 0.5018\n",
      "Epoch 51/100\n",
      "Train Loss: 1.2547 Acc: 0.4969\n",
      "Val Loss: 1.3218 Acc: 0.5150\n",
      "Epoch 52/100\n",
      "Train Loss: 1.2518 Acc: 0.4952\n",
      "Val Loss: 1.3122 Acc: 0.5147\n",
      "Epoch 53/100\n",
      "Train Loss: 1.2448 Acc: 0.4986\n",
      "Val Loss: 1.3154 Acc: 0.5178\n",
      "Epoch 54/100\n",
      "Train Loss: 1.2689 Acc: 0.4897\n",
      "Val Loss: 1.2930 Acc: 0.5065\n",
      "Epoch 55/100\n",
      "Train Loss: 1.2436 Acc: 0.4993\n",
      "Val Loss: 1.3480 Acc: 0.5188\n",
      "Epoch 56/100\n",
      "Train Loss: 1.2528 Acc: 0.4976\n",
      "Val Loss: 1.2819 Acc: 0.5081\n",
      "Epoch 57/100\n",
      "Train Loss: 1.2416 Acc: 0.4983\n",
      "Val Loss: 1.3040 Acc: 0.5244\n",
      "Epoch 58/100\n",
      "Train Loss: 1.2540 Acc: 0.4942\n",
      "Val Loss: 1.2814 Acc: 0.5193\n",
      "Epoch 59/100\n",
      "Train Loss: 1.2253 Acc: 0.5011\n",
      "Val Loss: 1.3014 Acc: 0.5206\n",
      "Epoch 60/100\n",
      "Train Loss: 1.2493 Acc: 0.4961\n",
      "Val Loss: 1.2878 Acc: 0.4970\n",
      "Epoch 61/100\n",
      "Train Loss: 1.2426 Acc: 0.4960\n",
      "Val Loss: 1.3194 Acc: 0.5147\n",
      "Epoch 62/100\n",
      "Train Loss: 1.2383 Acc: 0.4948\n",
      "Val Loss: 1.3228 Acc: 0.5185\n",
      "Epoch 63/100\n",
      "Train Loss: 1.2375 Acc: 0.4987\n",
      "Val Loss: 1.3039 Acc: 0.5126\n",
      "Epoch 64/100\n",
      "Train Loss: 1.2410 Acc: 0.5027\n",
      "Val Loss: 1.2915 Acc: 0.5228\n",
      "Epoch 65/100\n",
      "Train Loss: 1.2269 Acc: 0.5067\n",
      "Val Loss: 1.3532 Acc: 0.5129\n",
      "Epoch 66/100\n",
      "Train Loss: 1.2136 Acc: 0.5041\n",
      "Val Loss: 1.3029 Acc: 0.5114\n",
      "Epoch 67/100\n",
      "Train Loss: 1.2313 Acc: 0.4999\n",
      "Val Loss: 1.3165 Acc: 0.5226\n",
      "Epoch 68/100\n",
      "Train Loss: 1.2264 Acc: 0.5025\n",
      "Val Loss: 1.3241 Acc: 0.5214\n",
      "Epoch 69/100\n",
      "Train Loss: 1.2079 Acc: 0.5040\n",
      "Val Loss: 1.3285 Acc: 0.5200\n",
      "Epoch 70/100\n",
      "Train Loss: 1.2252 Acc: 0.5036\n",
      "Val Loss: 1.2893 Acc: 0.5150\n",
      "Epoch 71/100\n",
      "Train Loss: 1.2314 Acc: 0.4988\n",
      "Val Loss: 1.3029 Acc: 0.5115\n",
      "Epoch 72/100\n",
      "Train Loss: 1.2218 Acc: 0.5059\n",
      "Val Loss: 1.3167 Acc: 0.5131\n",
      "Epoch 73/100\n",
      "Train Loss: 1.2106 Acc: 0.5067\n",
      "Val Loss: 1.2975 Acc: 0.5148\n",
      "Epoch 74/100\n",
      "Train Loss: 1.2048 Acc: 0.5083\n",
      "Val Loss: 1.2869 Acc: 0.5261\n",
      "Epoch 75/100\n",
      "Train Loss: 1.2299 Acc: 0.4967\n",
      "Val Loss: 1.2704 Acc: 0.5218\n",
      "Epoch 76/100\n",
      "Train Loss: 1.2007 Acc: 0.5127\n",
      "Val Loss: 1.3275 Acc: 0.5356\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100):\n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_acc = train_correct.double() / len(train_loader.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels.data)\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_acc = val_correct.double() / len(val_loader.dataset)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print(f'Train Loss: {train_loss:.4f} Train Acc: {train_acc:.4f}')\n",
    "        print(f'Val Loss: {val_loss:.4f} Val Acc: {val_acc:.4f}')\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "    \n",
    "    print(f'Best val Acc: {best_val_acc:.4f}')\n",
    "\n",
    "# Assuming model, class_weights, train_loader, and val_loader are defined\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Ensure model is on the correct device\n",
    "model = model.to(device)\n",
    "\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "test_correct = 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_correct += torch.sum(preds == labels.data)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "test_acc = test_correct.double() / len(test_loader.dataset)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(y_true, y_pred, target_names=list(train_dataset.dataset.class_to_idx.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Out the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_expression(img_path, model):\n",
    "    model.eval()\n",
    "    img = Image.open(img_path).convert('L')\n",
    "    img = test_transform(img).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(img)\n",
    "        probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "        _, predicted_idx = torch.max(output, 1)\n",
    "    \n",
    "    class_names = list(train_dataset.dataset.class_to_idx.keys())\n",
    "    predicted_class = class_names[predicted_idx.item()]\n",
    "    confidence = probabilities[0][predicted_idx.item()].item()\n",
    "    \n",
    "    plt.imshow(Image.open(img_path).convert('L'), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Predicted: {predicted_class}\\nConfidence: {confidence:.2f}\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Probabilities for each class:\")\n",
    "    for class_name, prob in zip(class_names, probabilities[0]):\n",
    "        print(f\"{class_name}: {prob:.4f}\")\n",
    "\n",
    "# Example usage:\n",
    "# predict_expression('path/to/your/test/image.jpg', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'expression_classification_model.pth')\n",
    "print(\"Model saved as 'expression_classification_model.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and use the saved model\n",
    "loaded_model = ExpressionClassifier().to(device)\n",
    "loaded_model.load_state_dict(torch.load('expression_classification_model.pth'))\n",
    "loaded_model.eval()\n",
    "\n",
    "print(\"Loaded model:\", loaded_model)\n",
    "\n",
    "# You can now use the loaded_model to make predictions\n",
    "# For example:\n",
    "# predict_expression('path/to/your/test/image.jpg', loaded_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Some Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(dataloader):\n",
    "    images, labels = next(iter(dataloader))\n",
    "    images = images.numpy()\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    for i in range(25):\n",
    "        ax = fig.add_subplot(5, 5, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(np.squeeze(images[i]), cmap='gray')\n",
    "        ax.set_title(f\"{list(train_dataset.dataset.class_to_idx.keys())[labels[i]]}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Visualizing a batch of training images:\")\n",
    "show_batch(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
    "    ax1.plot(history['train_loss'], label='train loss')\n",
    "    ax1.plot(history['val_loss'], label='validation loss')\n",
    "    ax1.set_title('Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history['train_acc'], label='train accuracy')\n",
    "    ax2.plot(history['val_acc'], label='validation accuracy')\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Assuming you've stored the history during training\n",
    "# plot_performance(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misclassified Images Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_misclassified(model, test_loader, num_images=25):\n",
    "    model.eval()\n",
    "    misclassified_images = []\n",
    "    misclassified_labels = []\n",
    "    misclassified_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            for i in range(len(preds)):\n",
    "                if preds[i] != labels[i]:\n",
    "                    misclassified_images.append(images[i].cpu())\n",
    "                    misclassified_labels.append(labels[i].cpu())\n",
    "                    misclassified_preds.append(preds[i].cpu())\n",
    "                    \n",
    "                    if len(misclassified_images) == num_images:\n",
    "                        break\n",
    "            \n",
    "            if len(misclassified_images) == num_images:\n",
    "                break\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    for i in range(num_images):\n",
    "        ax = fig.add_subplot(5, 5, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(np.squeeze(misclassified_images[i]), cmap='gray')\n",
    "        ax.set_title(f\"True: {list(train_dataset.dataset.class_to_idx.keys())[misclassified_labels[i]]}\\nPred: {list(train_dataset.dataset.class_to_idx.keys())[misclassified_preds[i]]}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Visualizing misclassified images:\")\n",
    "show_misclassified(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
