{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program is referenced and modified from:\n",
    "> https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5  \n",
    "\n",
    "Reference article explaining how to improve the program:\n",
    "> https://david-exiga.medium.com/music-generation-using-lstm-neural-networks-44f6780a4c5  \n",
    "\n",
    "Additional Chinese program explanation:\n",
    "> https://github.com/xitu/gold-miner/blob/master/TODO1/how-to-generate-music-using-a-lstm-neural-network-in-keras.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: music21 in /usr/local/lib/python3.10/dist-packages (9.3.0)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.7.0)\n",
      "Requirement already satisfied: tensorflow[and-cuda] in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
      "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from music21) (5.2.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from music21) (1.4.2)\n",
      "Requirement already satisfied: jsonpickle in /usr/local/lib/python3.10/dist-packages (from music21) (4.0.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from music21) (3.9.3)\n",
      "Requirement already satisfied: more-itertools in /usr/lib/python3/dist-packages (from music21) (8.10.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from music21) (1.26.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from music21) (2.31.0)\n",
      "Requirement already satisfied: webcolors>=1.5 in /usr/local/lib/python3.10/dist-packages (from music21) (1.13)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.12.1)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\n",
      "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (23.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (5.29.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (69.0.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow[and-cuda]) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (2.18.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (0.37.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.5.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (12.5.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.5.82 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (12.5.82)\n",
      "Requirement already satisfied: nvidia-cuda-nvcc-cu12==12.5.82 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (12.5.82)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.5.82 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (12.5.82)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.5.82 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (12.5.82)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.3.0.75 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (9.3.0.75)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.3.61 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (11.2.3.61)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.6.82 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (10.3.6.82)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.3.83 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (11.6.3.83)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (12.5.1.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.5.82 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (12.5.82)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.42.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->music21) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->music21) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->music21) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->music21) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (3.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->music21) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (2.8.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (2.1.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install dependency \n",
    "# music21 Introduction: https://juejin.cn/post/7063827463058489352\n",
    "! pip install music21 keras tensorflow[and-cuda] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reading files\n",
    "import glob\n",
    "# array processing\n",
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "# keras for building deep learning model\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, TimeDistributed\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all notes and chords from midi files in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ./midi_songs/1.mid\n",
      "Parsing ./midi_songs/2.mid\n",
      "Parsing ./midi_songs/3.mid\n",
      "Parsing ./midi_songs/4.mid\n",
      "Parsing ./midi_songs/5.mid\n",
      "Parsing ./midi_songs/6.mid\n",
      "Parsing ./midi_songs/Ghosthack-AC22_Melody Loop Blue_Em 120BPM.mid\n",
      "Parsing ./midi_songs/Ghosthack-AC22_Melody Loop Questions_Gm 126BPM.mid\n",
      "Parsing ./midi_songs/Ghosthack-AC22_Melody Loop Closer_Fm 125BPM.mid\n",
      "Parsing ./midi_songs/Ghosthack-AC22_Melody Loop Aurora_Am 140BPM.mid\n",
      "Parsing ./midi_songs/Ghosthack-AC22_Melody Loop Alone_Dm 126BPM.mid\n",
      "Parsing ./midi_songs/Ghosthack-AC22_Melody Loop Turbo_Fm 130BPM.mid\n",
      "Parsing ./midi_songs/Ghosthack-AC22_Melody Loop Stay_Cm 126BPM.mid\n",
      "Parsing ./midi_songs/Ghosthack-AC22_Melody Loop Elements_Fm 126BPM.mid\n",
      "Parsing ./midi_songs/Ghosthack-AC22_Melody Loop Waterfall_Fm 140BPM.mid\n",
      "Parsing ./midi_songs/Ghosthack-AC22_Melody Loop Lovesick_Gm 126BPM.mid\n",
      "Parsing ./midi_songs/Ghosthack-AC22_Melody Loop Crusader_Cm 140BPM.mid\n",
      "Parsing ./midi_songs/Ghosthack-AC22_Melody Loop Future_Am 126BPM.mid\n",
      "Parsing ./midi_songs/Ghosthack-AC22_Melody Loop Buster_Cm 126BPM.mid\n",
      "Parsing ./midi_songs/Ghosthack-AC22_Melody Loop Ravers_D#m 130BPM.mid\n",
      "Parsing ./midi_songs/Ghosthack-AC22_Melody Loop Rebels_Cm 126BPM.mid\n",
      "Parsing ./midi_songs/Ghosthack-AC22_Melody Loop Burning_Dm 126BPM.mid\n",
      "Parsing ./midi_songs/Ghosthack-AC22_Melody Loop Lionheart_Gm 126BPM.mid\n",
      "Parsing ./midi_songs/Ghosthack-AC22_Melody Loop Resonate_Em 128BPM.mid\n",
      "Parsing ./midi_songs/Ghosthack-AC22_Melody Loop Darkness_Fm 126BPM.mid\n",
      "Parsing ./midi_songs/Ghosthack-AC22_Melody Loop Unity_D#m 130BPM.mid\n",
      "Parsing ./midi_songs/Ghosthack-AC22_Melody Loop Space_Em 126BPM.mid\n",
      "Parsing ./midi_songs/Ghosthack-AC22_Melody Loop Switch_Cm 95BPM.mid\n",
      "Parsing ./midi_songs/Ghosthack-AC22_Melody Loop Rave Machine_Dm 126BPM.mid\n",
      "Parsing ./midi_songs/Ghosthack-AC22_Melody Loop Pegasus_F#m 128BPM.mid\n",
      "Parsing ./midi_songs/Ghosthack-AC22_Melody Loop Reasons_Em 128BPM.mid\n",
      "Parsing ./midi_songs/Bohemian Rhapsody.mid\n",
      "Total notes and chords extracted: 1833\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Extract all notes and chords from MIDI files in a directory.\n",
    "\n",
    "This script uses music21 to process MIDI files. It reads all `.mid` files in the \n",
    "specified directory, extracts notes and chords, and appends them to the `notes` list.\n",
    "\"\"\"\n",
    "\n",
    "# Import necessary modules from music21 for MIDI processing\n",
    "from music21 import converter, instrument, note, chord\n",
    "import glob\n",
    "\n",
    "# List to store all notes and chords from the MIDI files\n",
    "notes = []\n",
    "\n",
    "# Specify the path to the MIDI files (modify as needed)\n",
    "midi_path = \"./midi_songs/*.mid\"\n",
    "\n",
    "# Loop through all MIDI files in the specified directory\n",
    "for file in glob.glob(midi_path):\n",
    "    print(f\"Parsing {file}\")\n",
    "    \n",
    "    # Parse the MIDI file using music21\n",
    "    midi = converter.parse(file)\n",
    "    \n",
    "    # Initialize a variable to hold notes and chords to be parsed\n",
    "    notes_to_parse = None\n",
    "\n",
    "    try:\n",
    "        # If the MIDI file contains instrument parts, extract the first part\n",
    "        s2 = instrument.partitionByInstrument(midi)\n",
    "        notes_to_parse = s2.parts[0].recurse()  # Access notes recursively\n",
    "    except AttributeError:\n",
    "        # If no instrument parts, use the flat structure to access notes\n",
    "        notes_to_parse = midi.flat.notes\n",
    "\n",
    "    # Extract notes and chords from the parsed MIDI data\n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note):\n",
    "            # If the element is a Note, extract its pitch as a string\n",
    "            notes.append(str(element.pitch))\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            # If the element is a Chord, extract its normal order as a string\n",
    "            notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "# Output the total number of notes and chords extracted\n",
    "print(f\"Total notes and chords extracted: {len(notes)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare input and output for neural network use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Explanation of Variables =====\n",
      "\n",
      "notes: A list containing all the musical notes as strings.\n",
      "Total number of notes in the score: 1833\n",
      "Total unique note types in the score: 113\n",
      "Unique note types: ['0', '0.3', '0.3.7', '0.4', '0.4.7', '0.5', '1.3.5.8', '1.3.8', '1.5.6.8', '1.5.8', '10', '10.1.3.6', '10.1.5', '10.11.3.6', '10.2.5', '11.3.6', '2', '2.5', '2.5.9', '2.6', '2.7', '3.5.6.10', '3.6.10', '3.6.8.11', '3.7', '3.7.10', '3.9', '4.5', '4.7', '4.9', '5', '5.10', '5.8', '5.8.0', '5.8.10.1', '5.9', '5.9.0', '7', '7.0', '7.10', '7.10.2', '7.11.2', '7.9', '8.0', '9', '9.0', '9.0.4', '9.2', 'A2', 'A3', 'A4', 'A5', 'A6', 'B-2', 'B-3', 'B-4', 'B-5', 'B0', 'B1', 'B2', 'B3', 'B4', 'B5', 'C#1', 'C#2', 'C#3', 'C#4', 'C#5', 'C#6', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'D2', 'D3', 'D4', 'D5', 'D6', 'E-1', 'E-2', 'E-3', 'E-4', 'E-5', 'E-6', 'E-7', 'E2', 'E3', 'E4', 'E5', 'E6', 'F#2', 'F#3', 'F#4', 'F#5', 'F#6', 'F2', 'F3', 'F4', 'F5', 'F6', 'G#1', 'G#2', 'G#3', 'G#4', 'G#5', 'G1', 'G2', 'G3', 'G4', 'G5', 'G6']\n",
      "Mapping of note types to IDs: {'0': 0, '0.3': 1, '0.3.7': 2, '0.4': 3, '0.4.7': 4, '0.5': 5, '1.3.5.8': 6, '1.3.8': 7, '1.5.6.8': 8, '1.5.8': 9, '10': 10, '10.1.3.6': 11, '10.1.5': 12, '10.11.3.6': 13, '10.2.5': 14, '11.3.6': 15, '2': 16, '2.5': 17, '2.5.9': 18, '2.6': 19, '2.7': 20, '3.5.6.10': 21, '3.6.10': 22, '3.6.8.11': 23, '3.7': 24, '3.7.10': 25, '3.9': 26, '4.5': 27, '4.7': 28, '4.9': 29, '5': 30, '5.10': 31, '5.8': 32, '5.8.0': 33, '5.8.10.1': 34, '5.9': 35, '5.9.0': 36, '7': 37, '7.0': 38, '7.10': 39, '7.10.2': 40, '7.11.2': 41, '7.9': 42, '8.0': 43, '9': 44, '9.0': 45, '9.0.4': 46, '9.2': 47, 'A2': 48, 'A3': 49, 'A4': 50, 'A5': 51, 'A6': 52, 'B-2': 53, 'B-3': 54, 'B-4': 55, 'B-5': 56, 'B0': 57, 'B1': 58, 'B2': 59, 'B3': 60, 'B4': 61, 'B5': 62, 'C#1': 63, 'C#2': 64, 'C#3': 65, 'C#4': 66, 'C#5': 67, 'C#6': 68, 'C1': 69, 'C2': 70, 'C3': 71, 'C4': 72, 'C5': 73, 'C6': 74, 'D2': 75, 'D3': 76, 'D4': 77, 'D5': 78, 'D6': 79, 'E-1': 80, 'E-2': 81, 'E-3': 82, 'E-4': 83, 'E-5': 84, 'E-6': 85, 'E-7': 86, 'E2': 87, 'E3': 88, 'E4': 89, 'E5': 90, 'E6': 91, 'F#2': 92, 'F#3': 93, 'F#4': 94, 'F#5': 95, 'F#6': 96, 'F2': 97, 'F3': 98, 'F4': 99, 'F5': 100, 'F6': 101, 'G#1': 102, 'G#2': 103, 'G#3': 104, 'G#4': 105, 'G#5': 106, 'G1': 107, 'G2': 108, 'G3': 109, 'G4': 110, 'G5': 111, 'G6': 112}\n",
      "\n",
      "===================\n",
      "\n",
      "Total notes: 1833\n",
      "Each 100 notes are converted into a training data set.\n",
      "network_input: 1733 sequences, each containing 100 numeric IDs.\n",
      "network_output: 1733 numeric IDs, each corresponding to the next note in the sequence.\n",
      "\n",
      "===================\n",
      "\n",
      "Notes from index sequence_length - 10 to sequence_length:\n",
      "['A5', 'D6', 'E2', 'D5', 'E5', 'B5', 'E2', 'E5', 'C3', 'C3']\n",
      "Corresponding numeric IDs:\n",
      "[51, 79, 87, 78, 90, 62, 87, 90, 71, 71]\n",
      "\n",
      "Last 10 IDs of the 0th sequence in network_input: [51, 79, 87, 78, 90, 62, 87, 90, 71, 71]\n",
      "Last 10 IDs of the 1st sequence in network_input: [79, 87, 78, 90, 62, 87, 90, 71, 71, 71]\n",
      "Last 10 IDs of the 2nd sequence in network_input: [87, 78, 90, 62, 87, 90, 71, 71, 71, 71]\n",
      "First three outputs in network_output: [71, 71, 90]\n",
      "\n",
      "===== After Reshaping Data =====\n",
      "\n",
      "normalized_input.shape: (1733, 100, 1)\n",
      "network_output.shape: (1733, 113)\n"
     ]
    }
   ],
   "source": [
    "# Prepare inputs and outputs for neural network\n",
    "\n",
    "# Get the number of unique note names\n",
    "n_vocab = len(set(notes))\n",
    "\n",
    "# Get the sorted list of unique note names\n",
    "pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "# Create a dictionary mapping each note to a corresponding numeric ID (e.g., C4 -> 25)\n",
    "note_to_int = {note: number for number, note in enumerate(pitchnames)}\n",
    "\n",
    "print(\"\\n===== Explanation of Variables =====\\n\")\n",
    "print(\"notes: A list containing all the musical notes as strings.\")\n",
    "print(f\"Total number of notes in the score: {len(notes)}\")\n",
    "print(f\"Total unique note types in the score: {n_vocab}\")\n",
    "print(f\"Unique note types: {pitchnames}\")\n",
    "print(f\"Mapping of note types to IDs: {note_to_int}\")\n",
    "\n",
    "# Length of the input sequence for training\n",
    "sequence_length = 100\n",
    "\n",
    "# Create input and output sequences\n",
    "network_input = []\n",
    "network_output = []\n",
    "\n",
    "# Ensure the notes list is long enough for the sequence length\n",
    "if len(notes) > sequence_length:\n",
    "    for i in range(len(notes) - sequence_length):\n",
    "        # Input sequence of notes\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        # Corresponding output note\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "\n",
    "        # Convert input sequence to numeric format\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        # Convert output note to numeric format\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    print(\"\\n===================\\n\")\n",
    "    print(f\"Total notes: {len(notes)}\")\n",
    "    print(f\"Each {sequence_length} notes are converted into a training data set.\")\n",
    "    print(f\"network_input: {len(network_input)} sequences, each containing {len(network_input[0])} numeric IDs.\")\n",
    "    print(f\"network_output: {len(network_output)} numeric IDs, each corresponding to the next note in the sequence.\")\n",
    "    print(\"\\n===================\\n\")\n",
    "    print(\"Notes from index sequence_length - 10 to sequence_length:\")\n",
    "    print(notes[sequence_length-10:sequence_length])\n",
    "    print(\"Corresponding numeric IDs:\")\n",
    "    print([note_to_int[char] for char in notes[sequence_length-10:sequence_length]])\n",
    "    print(\"\")\n",
    "    print(f\"Last 10 IDs of the 0th sequence in network_input: {network_input[0][sequence_length-10:sequence_length]}\")\n",
    "    print(f\"Last 10 IDs of the 1st sequence in network_input: {network_input[1][sequence_length-10:sequence_length]}\")\n",
    "    print(f\"Last 10 IDs of the 2nd sequence in network_input: {network_input[2][sequence_length-10:sequence_length]}\")\n",
    "    print(\"First three outputs in network_output:\", network_output[0:3])\n",
    "\n",
    "    # Number of patterns\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # Reshape input for LSTM compatibility\n",
    "    normalized_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "\n",
    "    # Normalize input\n",
    "    normalized_input = normalized_input / float(n_vocab)\n",
    "\n",
    "    # Convert output to categorical format\n",
    "    network_output = to_categorical(network_output, n_vocab)\n",
    "\n",
    "    print(\"\\n===== After Reshaping Data =====\\n\")\n",
    "    print(\"normalized_input.shape:\", normalized_input.shape)\n",
    "    print(\"network_output.shape:\", network_output.shape)\n",
    "\n",
    "else:\n",
    "    print(f\"Error: The notes list must be longer than the sequence length ({sequence_length}).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the structure of a neural network \n",
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,052,672</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">113</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">29,041</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">113</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │     \u001b[38;5;34m1,052,672\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │     \u001b[38;5;34m2,099,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m2,099,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m113\u001b[0m)            │        \u001b[38;5;34m29,041\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m113\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,414,513</span> (20.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,414,513\u001b[0m (20.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,412,977</span> (20.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,412,977\u001b[0m (20.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> (6.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,536\u001b[0m (6.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create the structure of the neural network using LSTM layers.\n",
    "\n",
    "This model is designed for sequence prediction tasks, leveraging the strengths of\n",
    "LSTM layers for processing sequential data like music notes and chords.\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first LSTM layer with return_sequences=True for stacked LSTM\n",
    "model.add(LSTM(\n",
    "    512,  # Number of units in the LSTM layer\n",
    "    input_shape=(normalized_input.shape[1], normalized_input.shape[2]),  # Input shape\n",
    "    recurrent_dropout=0.1,  # Dropout for recurrent connections\n",
    "    return_sequences=True  # Return sequences for stacking LSTM layers\n",
    "))\n",
    "\n",
    "# Add the second LSTM layer\n",
    "model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.1))\n",
    "\n",
    "# Add the third LSTM layer (no return_sequences since it's the last LSTM layer)\n",
    "model.add(LSTM(512))\n",
    "\n",
    "# Add Batch Normalization\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Add a Dropout layer to reduce overfitting\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# Add a Dense layer with 256 units and ReLU activation\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Add Batch Normalization\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Add another Dropout layer\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# Add the output layer with softmax activation\n",
    "model.add(Dense(n_vocab))  # n_vocab is the number of unique notes/chords\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compile the model with categorical crossentropy loss and RMSprop optimizer\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=RMSprop(learning_rate=0.001)  # Specify learning rate\n",
    ")\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733149582.782620   64003 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 5.2066\n",
      "Epoch 1: loss improved from inf to 5.01218, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 169ms/step - loss: 5.1936\n",
      "Epoch 2/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 4.4377\n",
      "Epoch 2: loss improved from 5.01218 to 4.38788, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 4.4344\n",
      "Epoch 3/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 4.2987\n",
      "Epoch 3: loss improved from 4.38788 to 4.27358, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 4.2971\n",
      "Epoch 4/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 4.0477\n",
      "Epoch 4: loss improved from 4.27358 to 4.09130, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 4.0506\n",
      "Epoch 5/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 4.0876\n",
      "Epoch 5: loss improved from 4.09130 to 4.03529, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 4.0841\n",
      "Epoch 6/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 4.0234\n",
      "Epoch 6: loss did not improve from 4.03529\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 4.0276\n",
      "Epoch 7/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 3.8624\n",
      "Epoch 7: loss improved from 4.03529 to 3.86647, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 3.8627\n",
      "Epoch 8/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 3.8426\n",
      "Epoch 8: loss improved from 3.86647 to 3.83273, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 3.8419\n",
      "Epoch 9/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 3.7337\n",
      "Epoch 9: loss improved from 3.83273 to 3.71454, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 3.7324\n",
      "Epoch 10/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 3.6255\n",
      "Epoch 10: loss improved from 3.71454 to 3.62522, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 3.6255\n",
      "Epoch 11/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 3.4950\n",
      "Epoch 11: loss improved from 3.62522 to 3.52833, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 3.4973\n",
      "Epoch 12/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 3.4743\n",
      "Epoch 12: loss improved from 3.52833 to 3.49534, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 3.4757\n",
      "Epoch 13/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 3.5734\n",
      "Epoch 13: loss improved from 3.49534 to 3.48374, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 3.5674\n",
      "Epoch 14/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 3.3963\n",
      "Epoch 14: loss improved from 3.48374 to 3.40958, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 3.3972\n",
      "Epoch 15/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 3.2851\n",
      "Epoch 15: loss improved from 3.40958 to 3.30673, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 3.2865\n",
      "Epoch 16/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 3.2829\n",
      "Epoch 16: loss improved from 3.30673 to 3.28644, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 3.2831\n",
      "Epoch 17/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 3.2795\n",
      "Epoch 17: loss improved from 3.28644 to 3.22069, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 3.2756\n",
      "Epoch 18/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 3.1287\n",
      "Epoch 18: loss improved from 3.22069 to 3.17420, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 3.1318\n",
      "Epoch 19/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 3.0708\n",
      "Epoch 19: loss improved from 3.17420 to 3.12860, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 3.0747\n",
      "Epoch 20/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 3.0105\n",
      "Epoch 20: loss improved from 3.12860 to 3.04023, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 3.0124\n",
      "Epoch 21/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 3.0507\n",
      "Epoch 21: loss did not improve from 3.04023\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 3.0508\n",
      "Epoch 22/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 2.9690\n",
      "Epoch 22: loss improved from 3.04023 to 2.96268, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 2.9686\n",
      "Epoch 23/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 2.8744\n",
      "Epoch 23: loss improved from 2.96268 to 2.91412, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 2.8770\n",
      "Epoch 24/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 2.8407\n",
      "Epoch 24: loss improved from 2.91412 to 2.89964, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 2.8447\n",
      "Epoch 25/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 2.8707\n",
      "Epoch 25: loss improved from 2.89964 to 2.86803, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 2.8706\n",
      "Epoch 26/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 2.7937\n",
      "Epoch 26: loss improved from 2.86803 to 2.79882, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 2.7940\n",
      "Epoch 27/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 2.7006\n",
      "Epoch 27: loss improved from 2.79882 to 2.73999, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 2.7032\n",
      "Epoch 28/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 2.6620\n",
      "Epoch 28: loss improved from 2.73999 to 2.69508, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 2.6642\n",
      "Epoch 29/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 2.6004\n",
      "Epoch 29: loss improved from 2.69508 to 2.66902, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 2.6050\n",
      "Epoch 30/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 2.5938\n",
      "Epoch 30: loss improved from 2.66902 to 2.65355, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 2.5978\n",
      "Epoch 31/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 2.5415\n",
      "Epoch 31: loss improved from 2.65355 to 2.58111, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 2.5442\n",
      "Epoch 32/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 2.4964\n",
      "Epoch 32: loss improved from 2.58111 to 2.54230, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 2.4995\n",
      "Epoch 33/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 2.5152\n",
      "Epoch 33: loss improved from 2.54230 to 2.49831, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 2.5140\n",
      "Epoch 34/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 2.4242\n",
      "Epoch 34: loss improved from 2.49831 to 2.42478, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 2.4242\n",
      "Epoch 35/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 2.3235\n",
      "Epoch 35: loss improved from 2.42478 to 2.40655, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 2.3290\n",
      "Epoch 36/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 2.3245\n",
      "Epoch 36: loss improved from 2.40655 to 2.35664, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 2.3266\n",
      "Epoch 37/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 2.2499\n",
      "Epoch 37: loss improved from 2.35664 to 2.27200, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 2.2513\n",
      "Epoch 38/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 2.2026\n",
      "Epoch 38: loss improved from 2.27200 to 2.22717, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 2.2042\n",
      "Epoch 39/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 2.1948\n",
      "Epoch 39: loss did not improve from 2.22717\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 2.1982\n",
      "Epoch 40/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 2.1083\n",
      "Epoch 40: loss improved from 2.22717 to 2.10600, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 2.1081\n",
      "Epoch 41/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 2.0711\n",
      "Epoch 41: loss improved from 2.10600 to 2.09503, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 2.0727\n",
      "Epoch 42/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 2.0605\n",
      "Epoch 42: loss did not improve from 2.09503\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 2.0638\n",
      "Epoch 43/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 1.8887\n",
      "Epoch 43: loss improved from 2.09503 to 1.93082, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 1.8915\n",
      "Epoch 44/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 1.9974\n",
      "Epoch 44: loss did not improve from 1.93082\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 1.9944\n",
      "Epoch 45/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 1.8619\n",
      "Epoch 45: loss improved from 1.93082 to 1.85570, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 1.8615\n",
      "Epoch 46/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 1.8436\n",
      "Epoch 46: loss improved from 1.85570 to 1.81363, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 1.8416\n",
      "Epoch 47/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 1.7437\n",
      "Epoch 47: loss improved from 1.81363 to 1.77679, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 1.7459\n",
      "Epoch 48/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 1.6716\n",
      "Epoch 48: loss improved from 1.77679 to 1.69622, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 1.6733\n",
      "Epoch 49/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 1.6459\n",
      "Epoch 49: loss improved from 1.69622 to 1.65781, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 1.6467\n",
      "Epoch 50/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 1.5868\n",
      "Epoch 50: loss improved from 1.65781 to 1.54204, saving model to best_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 1.5839\n",
      "Training complete! The best model has been saved as 'best_model.keras'.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train the neural network for generating music sequences.\n",
    "\n",
    "This process adjusts the weights of the model based on the provided input\n",
    "and output, enabling it to learn patterns in the musical dataset. Only the best model\n",
    "based on training loss will be saved.\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Define a callback to save the best model based on training loss\n",
    "callbacks = [\n",
    "    # Save only the best model based on minimum loss\n",
    "    ModelCheckpoint(\n",
    "        filepath='best_model.keras',  # Filepath to save the best model in .keras format\n",
    "        monitor='loss',               # Monitor training loss for improvement\n",
    "        save_best_only=True,          # Save only the best model weights\n",
    "        mode='min',                   # Minimize the monitored value (loss)\n",
    "        verbose=1\n",
    "    ),\n",
    "    # Stop training early if the loss stagnates\n",
    "    EarlyStopping(\n",
    "        monitor='loss', \n",
    "        patience=10,                  # Wait for 10 epochs of no improvement\n",
    "        restore_best_weights=True     # Load the best weights when stopping\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    normalized_input,  # Input data\n",
    "    network_output,    # Expected output\n",
    "    epochs=50,         # Total number of training epochs\n",
    "    batch_size=128,    # Size of each training batch\n",
    "    callbacks=callbacks,  # Attach callbacks\n",
    "    verbose=1          # Print progress during training\n",
    ")\n",
    "\n",
    "print(\"Training complete! The best model has been saved as 'best_model.keras'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the selected note starting point, predict the next note from the neural network and generate the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating notes...\n",
      "Note 0: A4\n",
      "Note 1: B4\n",
      "Note 2: B4\n",
      "Note 3: G#4\n",
      "Note 4: G#4\n",
      "Note 5: A4\n",
      "Note 6: 5.9\n",
      "Note 7: 5.9\n",
      "Note 8: 5.9\n",
      "Note 9: 5.9\n",
      "Note 10: 5.9\n",
      "Note 11: 5.9\n",
      "Note 12: 5.9\n",
      "Note 13: 4.5\n",
      "Note 14: 4.5\n",
      "Note 15: 5.9\n",
      "Note 16: 4.5\n",
      "Note 17: 4.9\n",
      "Note 18: 4.5\n",
      "Note 19: 4.5\n",
      "Note 20: 5.9\n",
      "Note 21: 5.9\n",
      "Note 22: 5.9\n",
      "Note 23: 5.9\n",
      "Note 24: 4.5\n",
      "Note 25: 5.9\n",
      "Note 26: 5.9\n",
      "Note 27: 1.5.6.8\n",
      "Note 28: 5.9\n",
      "Note 29: 1.5.6.8\n",
      "Note 30: 1.5.6.8\n",
      "Note 31: 0\n",
      "Note 32: 0.4.7\n",
      "Note 33: 0.4.7\n",
      "Note 34: B5\n",
      "Note 35: 3.6.10\n",
      "Note 36: 10\n",
      "Note 37: 10\n",
      "Note 38: 0\n",
      "Note 39: 0\n",
      "Note 40: 0.4.7\n",
      "Note 41: 0.4.7\n",
      "Note 42: 0.4.7\n",
      "Note 43: 0.4.7\n",
      "Note 44: 0.4.7\n",
      "Note 45: 0.4.7\n",
      "Note 46: 0.4.7\n",
      "Note 47: 0\n",
      "Note 48: 0.4.7\n",
      "Note 49: 5.9.0\n",
      "Note 50: 5.9.0\n",
      "Note 51: 5.9.0\n",
      "Note 52: 5.9.0\n",
      "Note 53: 5.9.0\n",
      "Note 54: 5.9.0\n",
      "Note 55: 5.9.0\n",
      "Note 56: 1.5.8\n",
      "Note 57: 0\n",
      "Note 58: C#6\n",
      "Note 59: 1.5.8\n",
      "Note 60: 1.5.8\n",
      "Note 61: 1.5.8\n",
      "Note 62: 1.5.8\n",
      "Note 63: 1.5.8\n",
      "Note 64: 1.5.6.8\n",
      "Note 65: 1.5.8\n",
      "Note 66: 10\n",
      "Note 67: E-7\n",
      "Note 68: 1.5.8\n",
      "Note 69: E3\n",
      "Note 70: E3\n",
      "Note 71: E3\n",
      "Note 72: E3\n",
      "Note 73: E2\n",
      "Note 74: E2\n",
      "Note 75: E2\n",
      "Note 76: B4\n",
      "Note 77: E4\n",
      "Note 78: G4\n",
      "Note 79: G4\n",
      "Note 80: B4\n",
      "Note 81: E4\n",
      "Note 82: F#4\n",
      "Note 83: G4\n",
      "Note 84: G4\n",
      "Note 85: E2\n",
      "Note 86: E4\n",
      "Note 87: F#4\n",
      "Note 88: B4\n",
      "Note 89: F#4\n",
      "Note 90: G4\n",
      "Note 91: B4\n",
      "Note 92: E4\n",
      "Note 93: G4\n",
      "Note 94: B4\n",
      "Note 95: B4\n",
      "Note 96: E4\n",
      "Note 97: G4\n",
      "Note 98: B4\n",
      "Note 99: B4\n",
      "Note 100: B4\n",
      "Note 101: E5\n",
      "Note 102: E5\n",
      "Note 103: B4\n",
      "Note 104: B4\n",
      "Note 105: E5\n",
      "Note 106: E5\n",
      "Note 107: B4\n",
      "Note 108: B4\n",
      "Note 109: B4\n",
      "Note 110: E5\n",
      "Note 111: E5\n",
      "Note 112: B4\n",
      "Note 113: B4\n",
      "Note 114: C5\n",
      "Note 115: E5\n",
      "Note 116: A4\n",
      "Note 117: B4\n",
      "Note 118: E5\n",
      "Note 119: G4\n",
      "Note 120: A4\n",
      "Note 121: B4\n",
      "Note 122: D5\n",
      "Note 123: G4\n",
      "Note 124: A4\n",
      "Note 125: B4\n",
      "Note 126: D5\n",
      "Note 127: G4\n",
      "Note 128: A4\n",
      "Note 129: B4\n",
      "Note 130: E5\n",
      "Note 131: A4\n",
      "Note 132: B5\n",
      "Note 133: B4\n",
      "Note 134: G4\n",
      "Note 135: A4\n",
      "Note 136: B4\n",
      "Note 137: B4\n",
      "Note 138: 3.6.10\n",
      "Note 139: B5\n",
      "Note 140: 3.6.10\n",
      "Note 141: 3.6.10\n",
      "Note 142: B5\n",
      "Note 143: B5\n",
      "Note 144: F4\n",
      "Note 145: A4\n",
      "Note 146: B4\n",
      "Note 147: 1.5.8\n",
      "Note 148: 5.9\n",
      "Note 149: 5.9\n",
      "Note 150: 11.3.6\n",
      "Note 151: 11.3.6\n",
      "Note 152: 5.9\n",
      "Note 153: 5.9\n",
      "Note 154: 11.3.6\n",
      "Note 155: 5.9\n",
      "Note 156: 5.9\n",
      "Note 157: 1.5.8\n",
      "Note 158: 1.5.8\n",
      "Note 159: 1.5.8\n",
      "Note 160: 1.5.8\n",
      "Note 161: C#6\n",
      "Note 162: 3.6.10\n",
      "Note 163: 3.6.10\n",
      "Note 164: 1.5.8\n",
      "Note 165: 1.5.8\n",
      "Note 166: 1.5.8\n",
      "Note 167: 3.6.10\n",
      "Note 168: 3.6.10\n",
      "Note 169: B5\n",
      "Note 170: 3.6.10\n",
      "Note 171: 0.4.7\n",
      "Note 172: 2.7\n",
      "Note 173: 0\n",
      "Note 174: 0\n",
      "Note 175: 1.5.6.8\n",
      "Note 176: B5\n",
      "Note 177: 3.6.10\n",
      "Note 178: 3.6.10\n",
      "Note 179: 0.4.7\n",
      "Note 180: 5.9.0\n",
      "Note 181: 1.5.8\n",
      "Note 182: 3.6.10\n",
      "Note 183: 3.6.10\n",
      "Note 184: 3.6.10\n",
      "Note 185: 3.6.10\n",
      "Note 186: 0.4.7\n",
      "Note 187: 0\n",
      "Note 188: 0\n",
      "Note 189: 0\n",
      "Note 190: 0\n",
      "Note 191: 0.4.7\n",
      "Note 192: 0.4.7\n",
      "Note 193: 7.10.2\n",
      "Note 194: 0.3.7\n",
      "Note 195: 0.4.7\n",
      "Note 196: 5.9.0\n",
      "Note 197: 7.10.2\n",
      "Note 198: 7.10.2\n",
      "Note 199: E3\n",
      "Note 200: B4\n",
      "Note 201: E4\n",
      "Note 202: E4\n",
      "Note 203: B4\n",
      "Note 204: E4\n",
      "Note 205: F#4\n",
      "Note 206: B4\n",
      "Note 207: E4\n",
      "Note 208: F#4\n",
      "Note 209: B4\n",
      "Note 210: E4\n",
      "Note 211: G4\n",
      "Note 212: G4\n",
      "Note 213: B4\n",
      "Note 214: E4\n",
      "Note 215: F#4\n",
      "Note 216: G4\n",
      "Note 217: G4\n",
      "Note 218: B4\n",
      "Note 219: E4\n",
      "Note 220: F#4\n",
      "Note 221: G4\n",
      "Note 222: B4\n",
      "Note 223: B4\n",
      "Note 224: E4\n",
      "Note 225: G4\n",
      "Note 226: G4\n",
      "Note 227: B4\n",
      "Note 228: E4\n",
      "Note 229: B4\n",
      "Note 230: B4\n",
      "Note 231: E5\n",
      "Note 232: A4\n",
      "Note 233: B4\n",
      "Note 234: C5\n",
      "Note 235: E5\n",
      "Note 236: E5\n",
      "Note 237: A4\n",
      "Note 238: B4\n",
      "Note 239: B4\n",
      "Note 240: E5\n",
      "Note 241: E5\n",
      "Note 242: B4\n",
      "Note 243: B4\n",
      "Note 244: E5\n",
      "Note 245: G4\n",
      "Note 246: A4\n",
      "Note 247: B4\n",
      "Note 248: E5\n",
      "Note 249: G4\n",
      "Note generation complete!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate music based on a starting sequence using the trained neural network.\n",
    "\n",
    "This process uses the model to predict the next notes and constructs\n",
    "a new sequence that can be converted into a MIDI file.\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "\n",
    "# Choose a random sequence from network_input as the starting point for generation\n",
    "start = numpy.random.randint(0, len(network_input) - 1)\n",
    "pattern = network_input[start]\n",
    "\n",
    "# Map integers back to their corresponding notes/chords\n",
    "int_to_note = {number: note for number, note in enumerate(pitchnames)}\n",
    "\n",
    "# Store the generated sequence\n",
    "prediction_output = []\n",
    "\n",
    "print(\"Generating notes...\")\n",
    "\n",
    "# Generate a sequence of notes (adjust the range for sequence length)\n",
    "for note_index in range(250):  # Generate more notes for richer output\n",
    "    # Prepare the input for prediction\n",
    "    prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    prediction_input = prediction_input / float(n_vocab)  # Normalize input\n",
    "\n",
    "    # Predict probabilities for the next note\n",
    "    prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "    # Add some randomness to predictions for creativity\n",
    "    top_indices = numpy.argsort(prediction[0])[-3:]  # Pick the top 3 predictions\n",
    "    index = random.choices(top_indices, weights=prediction[0][top_indices])[0]\n",
    "\n",
    "    # Map the predicted index to the corresponding note\n",
    "    result = int_to_note[index]\n",
    "    prediction_output.append(result)\n",
    "\n",
    "    print(f\"Note {note_index}: {result}\")\n",
    "\n",
    "    # Shift the prediction window and append the new note\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "\n",
    "print(\"Note generation complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert predicted output to notes and create a MIDI file from the notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file successfully created: generated_music.mid\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Convert the predicted output into a MIDI file.\n",
    "\n",
    "This script takes the generated sequence of notes and chords, creates\n",
    "corresponding MIDI objects, and saves them as a MIDI file.\n",
    "\"\"\"\n",
    "\n",
    "from music21 import stream, note, chord, instrument\n",
    "\n",
    "# Initialize variables for MIDI creation\n",
    "offset = 0  # Time spacing between notes/chords\n",
    "output_notes = []\n",
    "\n",
    "# Convert the predicted patterns into notes and chords\n",
    "for pattern in prediction_output:\n",
    "    # If the pattern represents a chord\n",
    "    if ('.' in pattern) or pattern.isdigit():\n",
    "        notes_in_chord = pattern.split('.')\n",
    "        notes = []\n",
    "        for current_note in notes_in_chord:\n",
    "            try:\n",
    "                # Convert the note number into a Note object\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            except ValueError:\n",
    "                print(f\"Skipped invalid note: {current_note}\")\n",
    "        # Create a Chord object from the notes\n",
    "        if notes:\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "    # If the pattern represents a single note\n",
    "    else:\n",
    "        try:\n",
    "            # Convert the pattern into a Note object\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating note '{pattern}': {e}\")\n",
    "\n",
    "    # Increment the offset for spacing\n",
    "    offset += 0.5\n",
    "\n",
    "# Create a music21 stream from the generated notes and chords\n",
    "midi_stream = stream.Stream(output_notes)\n",
    "\n",
    "# Save the stream as a MIDI file\n",
    "output_filename = 'generated_music.mid'\n",
    "try:\n",
    "    midi_stream.write('midi', fp=output_filename)\n",
    "    print(f\"MIDI file successfully created: {output_filename}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error writing MIDI file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
