{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e384a41-d32b-4738-aea9-bfe1f1feda2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.3)\n",
      "Requirement already satisfied: tensorflow[and-cuda] in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow[and-cuda]) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (3.6.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (0.37.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.5.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.5.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.82)\n",
      "Requirement already satisfied: nvidia-cuda-nvcc-cu12==12.5.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.82)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.5.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.82)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.5.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.82)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.3.0.75 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (9.3.0.75)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.3.61 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (11.2.3.61)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.6.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (10.3.6.82)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.3.83 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (11.6.3.83)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.1.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.1.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.5.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.82)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.54.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (163 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.44.0)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow[and-cuda]) (13.9.3)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow[and-cuda]) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow[and-cuda]) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (3.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow[and-cuda]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow[and-cuda]) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow[and-cuda]) (0.1.2)\n",
      "Downloading matplotlib-3.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m285.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.54.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m314.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m249.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.54.1 kiwisolver-1.4.7 matplotlib-3.9.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow[and-cuda] matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3923b71-6e53-4727-b9f0-370f5c72bc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.platform.build_info' has no attribute 'cuda_version_number'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorFlow version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, tf\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_info \u001b[38;5;28;01mas\u001b[39;00m tf_build_info\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mtf_build_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda_version_number\u001b[49m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCuDNN version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, tf_build_info\u001b[38;5;241m.\u001b[39mcudnn_version_number)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.python.platform.build_info' has no attribute 'cuda_version_number'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "from tensorflow.python.platform import build_info as tf_build_info\n",
    "print(\"CUDA version:\", tf_build_info.cuda_version_number)\n",
    "print(\"CuDNN version:\", tf_build_info.cudnn_version_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6fc6283",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cab9bfc",
   "metadata": {},
   "source": [
    "## Set random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6afafaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6054cb7c",
   "metadata": {},
   "source": [
    "## Load and preprocess MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3ae7132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Training data shape: (60000, 784)\n",
      "Test data shape: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load and preprocess MNIST data\n",
    "def load_and_preprocess_data():\n",
    "    # Load MNIST dataset\n",
    "    (x_train, _), (x_test, _) = mnist.load_data()\n",
    "    \n",
    "    # Normalize pixel values to [0, 1]\n",
    "    x_train = x_train.astype('float32') / 255.\n",
    "    x_test = x_test.astype('float32') / 255.\n",
    "    \n",
    "    # Flatten the images\n",
    "    x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "    x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "    \n",
    "    return x_train, x_test\n",
    "\n",
    "x_train, x_test = load_and_preprocess_data()\n",
    "print(\"Training data shape:\", x_train.shape)\n",
    "print(\"Test data shape:\", x_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61225ca",
   "metadata": {},
   "source": [
    "## Build the autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9f3dd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1730477689.841874     174 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43598 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:d2:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">785,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">500,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">125,250</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,032</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,250</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">125,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">501,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">784,784</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)           │       \u001b[38;5;34m785,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │       \u001b[38;5;34m500,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m)            │       \u001b[38;5;34m125,250\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m8,032\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m)            │         \u001b[38;5;34m8,250\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │       \u001b[38;5;34m125,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)           │       \u001b[38;5;34m501,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │       \u001b[38;5;34m784,784\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,838,316</span> (10.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,838,316\u001b[0m (10.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,838,316</span> (10.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,838,316\u001b[0m (10.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Build the autoencoder model\n",
    "def create_autoencoder(input_dim=784, encoding_dim=32):\n",
    "    # Encoder\n",
    "    encoder_input = layers.Input(shape=(input_dim,))\n",
    "    x = layers.Dense(1000, activation='relu')(encoder_input)\n",
    "    x = layers.Dense(500, activation='relu')(x)\n",
    "    x = layers.Dense(250, activation='relu')(x)\n",
    "    encoder_output = layers.Dense(encoding_dim, activation='relu', name='encoder')(x)\n",
    "    \n",
    "    # Decoder\n",
    "    decoder_input = layers.Dense(250, activation='relu')(encoder_output)\n",
    "    x = layers.Dense(500, activation='relu')(decoder_input)\n",
    "    x = layers.Dense(1000, activation='relu')(x)\n",
    "    decoder_output = layers.Dense(input_dim, activation='sigmoid')(x)\n",
    "    \n",
    "    # Create full autoencoder model\n",
    "    autoencoder = models.Model(encoder_input, decoder_output)\n",
    "    encoder = models.Model(encoder_input, encoder_output)\n",
    "    \n",
    "    return autoencoder, encoder\n",
    "\n",
    "autoencoder, encoder = create_autoencoder()\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320b86b8",
   "metadata": {},
   "source": [
    "## Train the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b401ee39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730477700.192141     525 service.cc:148] XLA service 0x7bf7bc00ecb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1730477700.192168     525 service.cc:156]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6\n",
      "2024-11-01 16:15:00.233704: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1730477700.463770     525 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2024-11-01 16:15:12.848406: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_292', 64 bytes spill stores, 64 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:12.951749: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_313', 64 bytes spill stores, 64 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:14.264092: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_313', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:14.369191: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_341', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:14.662605: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_292', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:15.258705: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_341', 100 bytes spill stores, 108 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:15.463732: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_292', 236 bytes spill stores, 236 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:15.953893: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_341', 44 bytes spill stores, 44 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:17.258538: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_327', 152 bytes spill stores, 152 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:17.960235: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_686', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:18.049326: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_355', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:18.865959: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_341', 168 bytes spill stores, 168 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:19.348624: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_313_0', 564 bytes spill stores, 528 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:19.467022: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_348', 24 bytes spill stores, 28 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:19.652974: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_292_0', 784 bytes spill stores, 736 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:19.859587: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_355_0', 784 bytes spill stores, 736 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:19.869827: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_348_0', 776 bytes spill stores, 724 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:20.164638: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_341', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:20.256485: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_313', 1304 bytes spill stores, 1444 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:20.748878: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_292', 904 bytes spill stores, 860 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:21.956227: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_696', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:22.757896: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_348', 900 bytes spill stores, 856 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:25.171256: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_341', 820 bytes spill stores, 756 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:25.666089: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_355', 64 bytes spill stores, 64 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:26.465938: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_348', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:26.592122: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_355', 236 bytes spill stores, 236 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:26.692397: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_355', 904 bytes spill stores, 860 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 68/469\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3710"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1730477729.820548     525 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m459/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2307"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-01 16:15:39.656822: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_313', 64 bytes spill stores, 64 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:39.958338: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_292', 236 bytes spill stores, 236 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:40.152379: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_292', 80 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:40.363567: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_698', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:41.251162: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_292', 28 bytes spill stores, 28 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:41.359750: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_292', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:42.158247: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_292', 4 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:42.158599: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_348', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:42.249271: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_313', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:42.256173: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_341', 80 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:42.552096: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_313', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:42.660228: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_327', 196 bytes spill stores, 196 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:42.757202: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_313', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:43.450611: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_688', 188 bytes spill stores, 188 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:43.753508: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_313', 1412 bytes spill stores, 1300 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:44.453209: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_313_0', 752 bytes spill stores, 576 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:45.156505: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_341', 52 bytes spill stores, 56 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:45.248724: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_292_0', 1060 bytes spill stores, 748 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:45.258779: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_292', 932 bytes spill stores, 772 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:45.958443: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_348', 932 bytes spill stores, 764 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:46.652944: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_355', 4 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:47.659321: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_355', 28 bytes spill stores, 28 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:48.159768: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_341', 744 bytes spill stores, 548 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:48.263076: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_334', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:48.461075: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_341', 112 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:48.756446: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_355', 80 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:48.962054: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_694', 168 bytes spill stores, 168 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:49.957460: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_341_0', 44 bytes spill stores, 44 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:51.962557: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_334', 28 bytes spill stores, 28 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:52.050762: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_348', 52 bytes spill stores, 52 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:52.652933: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_355', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:53.161650: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_341', 188 bytes spill stores, 188 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:53.457558: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_355', 236 bytes spill stores, 236 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:54.753368: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_348_0', 1044 bytes spill stores, 732 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:54.848051: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_698', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:54.861350: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_686', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:55.057282: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_696', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:56.158233: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_696', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:56.374056: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_686', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:56.454224: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_341', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:56.472516: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_355_0', 1060 bytes spill stores, 748 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:56.488522: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_688', 28 bytes spill stores, 28 bytes spill loads\n",
      "\n",
      "2024-11-01 16:15:56.740638: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_355', 932 bytes spill stores, 772 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2293"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-01 16:16:10.260355: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_32', 220 bytes spill stores, 228 bytes spill loads\n",
      "\n",
      "2024-11-01 16:16:10.695456: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_74', 220 bytes spill stores, 228 bytes spill loads\n",
      "\n",
      "2024-11-01 16:16:10.801501: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_60', 180 bytes spill stores, 180 bytes spill loads\n",
      "\n",
      "2024-11-01 16:16:10.831566: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 208 bytes spill stores, 208 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 90ms/step - loss: 0.2292 - val_loss: 0.1148\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1102 - val_loss: 0.1002\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0973 - val_loss: 0.0914\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0915 - val_loss: 0.0886\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0882 - val_loss: 0.0856\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0859 - val_loss: 0.0852\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0832 - val_loss: 0.0839\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0822 - val_loss: 0.0827\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0816 - val_loss: 0.0822\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0811 - val_loss: 0.0824\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0806 - val_loss: 0.0818\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0800 - val_loss: 0.0828\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0801 - val_loss: 0.0827\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0798 - val_loss: 0.0815\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0793 - val_loss: 0.0810\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0792 - val_loss: 0.0806\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0791 - val_loss: 0.0809\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0790 - val_loss: 0.0810\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0785 - val_loss: 0.0813\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the autoencoder\n",
    "def train_autoencoder(autoencoder, x_train, x_test):\n",
    "    # Compile the model\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    \n",
    "    # Train the model\n",
    "    history = autoencoder.fit(\n",
    "        x_train, x_train,  # Input and target are the same for autoencoder\n",
    "        epochs=20,  # Increased epochs for better convergence\n",
    "        batch_size=128,\n",
    "        shuffle=True,\n",
    "        validation_data=(x_test, x_test),\n",
    "        verbose=1  # Show training progress\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "history = train_autoencoder(autoencoder, x_train, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac47c19",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e1cbe19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-01 16:16:52.755045: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_33', 64 bytes spill stores, 64 bytes spill loads\n",
      "\n",
      "2024-11-01 16:16:55.049115: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_26', 408 bytes spill stores, 444 bytes spill loads\n",
      "\n",
      "2024-11-01 16:16:55.050351: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_33', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "2024-11-01 16:16:55.172990: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_26', 236 bytes spill stores, 236 bytes spill loads\n",
      "\n",
      "2024-11-01 16:16:55.616158: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_68', 408 bytes spill stores, 444 bytes spill loads\n",
      "\n",
      "2024-11-01 16:16:55.666346: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_54', 372 bytes spill stores, 404 bytes spill loads\n",
      "\n",
      "2024-11-01 16:16:55.676409: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_61', 396 bytes spill stores, 432 bytes spill loads\n",
      "\n",
      "2024-11-01 16:16:55.776038: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_68', 236 bytes spill stores, 236 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Visualize results\n",
    "def visualize_reconstructions(autoencoder, x_test):\n",
    "    # Predict reconstructions\n",
    "    decoded_imgs = autoencoder.predict(x_test)\n",
    "    \n",
    "    # Number of images to display\n",
    "    n = 10\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Original images\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        \n",
    "        # Reconstructed images\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(decoded_imgs[i].reshape(28, 28), cmap='gray')\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_reconstructions(autoencoder, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5993078e-a531-4bb9-a697-4003769b3a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
