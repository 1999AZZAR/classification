{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bddbed4-5536-4da1-86f7-673f1e7ee00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import necessary libraries\n",
    "import numpy as np\n",
    "import music21\n",
    "from tensorflow.keras.models import load_model\n",
    "from music21 import note, chord, stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8d7d686-f779-417d-a3be-462fbf6ffd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Helper functions\n",
    "def parse_midi_file(file_path):\n",
    "    \"\"\"Extract notes and chords from a MIDI file.\"\"\"\n",
    "    try:\n",
    "        midi_stream = music21.converter.parse(file_path)\n",
    "        notes = []\n",
    "        for element in midi_stream.flat.notes:\n",
    "            if isinstance(element, music21.note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, music21.chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "        return notes\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "def create_midi_file(predicted_notes, output_path):\n",
    "    \"\"\"Create a MIDI file from predicted notes.\"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    for note in predicted_notes:\n",
    "        if '.' in note or note.isdigit():\n",
    "            # Chord\n",
    "            chord_notes = [music21.note.Note(int(n)) for n in note.split('.')]\n",
    "            new_chord = music21.chord.Chord(chord_notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        else:\n",
    "            # Note\n",
    "            new_note = music21.note.Note(note)\n",
    "            new_note.offset = offset\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        offset += 0.5  # Add a fixed step for note spacing\n",
    "\n",
    "    midi_stream = music21.stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp=output_path)\n",
    "\n",
    "def prepare_input_sequence(notes, note_to_int, sequence_length):\n",
    "    \"\"\"Prepare the input sequence for the model.\"\"\"\n",
    "    int_sequence = [note_to_int[note] for note in notes if note in note_to_int]\n",
    "    pattern = int_sequence[-sequence_length:]\n",
    "    input_sequence = np.reshape(pattern, (1, sequence_length, 1))\n",
    "    input_sequence = input_sequence / float(len(note_to_int))\n",
    "    return input_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69225426-fb01-4756-bb5e-2f9fcaae6f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from best_lstm_music_model.keras.\n",
      "Unique notes in input: 33\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load the trained model and prepare data\n",
    "model_path = 'best_lstm_music_model.keras'  # Path to the saved model\n",
    "model = load_model(model_path)\n",
    "print(f\"Model loaded from {model_path}.\")\n",
    "\n",
    "input_midi_path = 'seed5.mid'  # Path to the input MIDI file\n",
    "output_midi_path = 'generated_variation.mid'  # Path to save the generated MIDI variation\n",
    "\n",
    "# Load and process the input MIDI file\n",
    "sequence_length = 50  # Same sequence length as used in training\n",
    "input_notes = parse_midi_file(input_midi_path)\n",
    "\n",
    "if not input_notes:\n",
    "    raise ValueError(\"No valid notes extracted from the input MIDI file.\")\n",
    "\n",
    "# Generate mapping from notes to integers and vice versa\n",
    "unique_notes = sorted(set(input_notes))\n",
    "note_to_int = {note: num for num, note in enumerate(unique_notes)}\n",
    "int_to_note = {num: note for note, num in note_to_int.items()}\n",
    "\n",
    "print(f\"Unique notes in input: {len(unique_notes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16bfb2b7-6455-4d1c-be56-ae0f5266d67f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 200 new notes.\n"
     ]
    }
   ],
   "source": [
    "def generate_variation(model, input_notes, note_to_int, int_to_note, sequence_length, num_notes):\n",
    "    generated_notes = []\n",
    "    \n",
    "    input_notes = input_notes[-sequence_length:]\n",
    "    input_notes_int = [note_to_int[note] for note in input_notes]\n",
    "    input_sequence = np.array(input_notes_int).reshape((1, sequence_length, 1))\n",
    "    \n",
    "    for _ in range(num_notes):\n",
    "        prediction = model.predict(input_sequence, verbose=0)\n",
    "        predicted_index = np.argmax(prediction)\n",
    "        \n",
    "        # Handle index out of range\n",
    "        if predicted_index >= len(int_to_note):\n",
    "            predicted_index = predicted_index % len(int_to_note)\n",
    "            \n",
    "        predicted_note = int_to_note[predicted_index]\n",
    "        \n",
    "        try:\n",
    "            if '.' in predicted_note:\n",
    "                notes_in_chord = predicted_note.split('.')\n",
    "                chord_notes = []\n",
    "                for current_note in notes_in_chord:\n",
    "                    try:\n",
    "                        new_note = note.Note(int(current_note))\n",
    "                        chord_notes.append(new_note)\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                n = chord.Chord(chord_notes) if chord_notes else note.Note(60)\n",
    "            else:\n",
    "                n = note.Note(int(predicted_note)) if predicted_note.isdigit() else note.Note(60)\n",
    "            \n",
    "            generated_notes.append(n)\n",
    "        except Exception:\n",
    "            generated_notes.append(note.Note(60))\n",
    "        \n",
    "        predicted_index_reshaped = np.array([[predicted_index]]).reshape((1, 1, 1))\n",
    "        input_sequence = np.append(input_sequence[:, 1:, :], predicted_index_reshaped, axis=1)\n",
    "    \n",
    "    score = stream.Score()\n",
    "    part = stream.Part()\n",
    "    for n in generated_notes:\n",
    "        part.append(n)\n",
    "    score.append(part)\n",
    "    \n",
    "    return score, generated_notes\n",
    "\n",
    "# Usage:\n",
    "num_notes_to_generate = 200\n",
    "score, generated_notes = generate_variation(model, input_notes, note_to_int, int_to_note, sequence_length, num_notes_to_generate)\n",
    "\n",
    "# Save the generated music\n",
    "score.write('midi', fp='generated_music.mid')\n",
    "print(f\"Generated {len(generated_notes)} new notes.\")\n",
    "\n",
    "# Optionally show or play the generated music\n",
    "score.show('midi')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
