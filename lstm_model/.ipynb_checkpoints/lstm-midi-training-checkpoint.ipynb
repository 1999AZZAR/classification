{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from music21 import converter, instrument, note, chord\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "source": [
    "MIDI_PATH = \"path/to/midi/folder/*.mid\"\n",
    "SEQUENCE_LENGTH = 100\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-prep",
   "metadata": {},
   "source": [
    "def get_notes():\n",
    "    notes = []\n",
    "    for file in glob.glob(MIDI_PATH):\n",
    "        midi = converter.parse(file)\n",
    "        parts = instrument.partitionByInstrument(midi)\n",
    "        \n",
    "        if parts:\n",
    "            notes_to_parse = parts.parts[0].recurse()\n",
    "        else:\n",
    "            notes_to_parse = midi.flat.notes\n",
    "            \n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "                \n",
    "    return notes\n",
    "\n",
    "def prepare_sequences(notes):\n",
    "    pitchnames = sorted(set(notes))\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "    \n",
    "    network_input = []\n",
    "    network_output = []\n",
    "    \n",
    "    for i in range(0, len(notes) - SEQUENCE_LENGTH):\n",
    "        sequence_in = notes[i:i + SEQUENCE_LENGTH]\n",
    "        sequence_out = notes[i + SEQUENCE_LENGTH]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "    \n",
    "    n_patterns = len(network_input)\n",
    "    network_input = np.reshape(network_input, (n_patterns, SEQUENCE_LENGTH, 1))\n",
    "    network_input = network_input / float(len(pitchnames))\n",
    "    network_output = tf.keras.utils.to_categorical(network_output)\n",
    "    \n",
    "    return network_input, network_output, len(pitchnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model",
   "metadata": {},
   "source": [
    "def create_model(n_vocab):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(512, input_shape=(SEQUENCE_LENGTH, 1), return_sequences=True))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(LSTM(512, return_sequences=True))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(LSTM(512))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(n_vocab, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train",
   "metadata": {},
   "source": [
    "# Get training data\n",
    "notes = get_notes()\n",
    "network_input, network_output, n_vocab = prepare_sequences(notes)\n",
    "\n",
    "# Create model\n",
    "model = create_model(n_vocab)\n",
    "\n",
    "# Callbacks\n",
    "filepath = \"weights-{epoch:02d}-{loss:.4f}.keras\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=10)\n",
    "\n",
    "# Train\n",
    "history = model.fit(network_input, network_output, \n",
    "                   epochs=EPOCHS, \n",
    "                   batch_size=BATCH_SIZE,\n",
    "                   callbacks=[checkpoint, early_stopping])\n",
    "\n",
    "# Save final model\n",
    "model.save('final_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Loss During Training')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  }
 ]
}
